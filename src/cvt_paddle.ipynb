{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from collections.abc import Iterable\n",
    "from numpy import repeat\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import paddle\n",
    "import numpy as np\n",
    "\n",
    "def PaddleRearrange(tensor:paddle.Tensor, pattern: str, **axes_lengths) -> paddle.Tensor:\n",
    "    x=np.array(tensor)\n",
    "    return paddle.to_tensor(rearrange(x,pattern,**axes_lengths))\n",
    "class RearrangeLayer(nn.Layer):\n",
    "    def __init__(self,pattern) :\n",
    "        super().__init__()\n",
    "        self.pattern=pattern\n",
    "    def forword(self,x:paddle.Tensor):\n",
    "        return PaddleRearrange(x,self.pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# From PyTorch internals\n",
    "\"\"\"对repeat进行封装，让代码更加健壮\"\"\"\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, Iterable):#如果已经是转换后的值，直接返回，不需要再做转换操作\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "\n",
    "    return parse\n",
    "to_1tuple = _ntuple(1)\n",
    "to_2tuple = _ntuple(2)\n",
    "to_3tuple = _ntuple(3)\n",
    "to_4tuple = _ntuple(4)\n",
    "to_ntuple = _ntuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理fp16(16位小数),按照fp32进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.LayerNorm):\n",
    "    \"\"\"Subclass torch's LayerNorm to handle fp16.\"\"\"\n",
    "\n",
    "    def forward(self, x: paddle.Tensor):\n",
    "        orig_type = x.dtype\n",
    "        ret = super().forward(x.type(paddle.float32))\n",
    "        return ret.type(orig_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重写GELU函数，降低处理精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickGELU(nn.Layer):\n",
    "    def forward(self, x: paddle.Tensor):\n",
    "        return x * paddle.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接网络，复用自 paddle vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Layer):\n",
    "    \"\"\" MLP module\n",
    "    Impl using nn.Linear and activation is GELU, dropout is applied.\n",
    "    Ops: fc -> act -> dropout -> fc -> dropout\n",
    "    Attributes:\n",
    "        fc1: nn.Linear\n",
    "        fc2: nn.Linear\n",
    "        act: GELU\n",
    "        dropout1: dropout after fc1\n",
    "        dropout2: dropout after fc2\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 embed_dim,\n",
    "                 mlp_ratio,\n",
    "                 dropout=0.):\n",
    "        super().__init__()\n",
    "        w_attr_1, b_attr_1 = self._init_weights()\n",
    "        self.fc1 = nn.Linear(embed_dim,\n",
    "                             int(embed_dim * mlp_ratio),\n",
    "                             weight_attr=w_attr_1,\n",
    "                             bias_attr=b_attr_1)\n",
    "\n",
    "        w_attr_2, b_attr_2 = self._init_weights()\n",
    "        self.fc2 = nn.Linear(int(embed_dim * mlp_ratio),\n",
    "                             embed_dim,\n",
    "                             weight_attr=w_attr_2,\n",
    "                             bias_attr=b_attr_2)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        weight_attr = paddle.ParamAttr(\n",
    "            initializer=nn.initializer.XavierUniform()) #default in pp: xavier\n",
    "        bias_attr = paddle.ParamAttr(\n",
    "            initializer=nn.initializer.Normal(std=1e-6)) #default in pp: zero\n",
    "        return weight_attr, bias_attr\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEmbed(nn.Layer):\n",
    "    \"\"\" Image to Conv Embedding\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 patch_size=7,\n",
    "                 in_chans=3,\n",
    "                 embed_dim=64,\n",
    "                 stride=4,\n",
    "                 padding=2,\n",
    "                 norm_layer=None):\n",
    "        super().__init__()\n",
    "        patch_size = to_2tuple(patch_size)#把patch初始化为一个正方形,这里是(7,7)\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "        self.proj = nn.Conv2D(\n",
    "            in_chans, embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=stride,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.proj(x)\n",
    "        print(x.shape)\n",
    "        B, C, H, W = x.shape#B个图片H*W的大小 C个通道(example：W==3:红黄蓝)\n",
    "        x = PaddleRearrange(x, 'b c h w -> b (h w) c')#对每个图片进行嵌入，相当于对每个图片线性的堆叠\n",
    "        if self.norm:\n",
    "            x = self.norm(x)\n",
    "        x = PaddleRearrange(x, 'b (h w) c -> b c h w', h=H, w=W)#把x回归原来的形状\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Layer):\n",
    "    \"\"\" Attention module\n",
    "    Attributes:\n",
    "        dim_in: numebr of input dim\n",
    "        dim_out: number of output dum\n",
    "        num_heads: \n",
    "        qkv_bias=False\n",
    "        attn_drop=0.,\n",
    "        proj_drop=0.\n",
    "        method='dw_bn' generate projection method \n",
    "        kernel_size=3  conv kernel size \n",
    "        stride_kv=1 calculat k,v with conv , with paramer stride \n",
    "        stride_q=1 calculat qwith conv , with paramer stride ,this stride can be different from stride_kv=1\n",
    "        padding_kv=1  calculat k,v with conv , with paramer paddding\n",
    "        padding_q=1 calculat q with conv , with paramer paddding\n",
    "        with_cls_token=True ,if label is given\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dim_in,\n",
    "                 dim_out,\n",
    "                 num_heads,\n",
    "                 qkv_bias=False,\n",
    "                 attn_drop=0.,\n",
    "                 proj_drop=0.,\n",
    "                 method='dw_bn',\n",
    "                 kernel_size=3,\n",
    "                 stride_kv=1,\n",
    "                 stride_q=1,\n",
    "                 padding_kv=1,\n",
    "                 padding_q=1,\n",
    "                 with_cls_token=True,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        #init to save the pararm\n",
    "        self.stride_kv = stride_kv\n",
    "        self.stride_q = stride_q\n",
    "        self.dim = dim_out\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = dim_out ** -0.5\n",
    "        self.with_cls_token = with_cls_token\n",
    "\n",
    "        # calculate q,k,v with conv\n",
    "\n",
    "        self.conv_proj_q = self._build_projection(\n",
    "            dim_in, dim_out, kernel_size, padding_q,\n",
    "            stride_q, 'linear' if method == 'avg' else method\n",
    "        )\n",
    "        self.conv_proj_k = self._build_projection(\n",
    "            dim_in, dim_out, kernel_size, padding_kv,\n",
    "            stride_kv, method\n",
    "        )\n",
    "        self.conv_proj_v = self._build_projection(\n",
    "            dim_in, dim_out, kernel_size, padding_kv,\n",
    "            stride_kv, method\n",
    "        )\n",
    "\n",
    "        # init parameters of q,k,v\n",
    "\n",
    "        self.proj_q = nn.Linear(dim_in, dim_out, bias=qkv_bias)\n",
    "        self.proj_k = nn.Linear(dim_in, dim_out, bias=qkv_bias)\n",
    "        self.proj_v = nn.Linear(dim_in, dim_out, bias=qkv_bias)\n",
    "\n",
    "        # init project other parameters\n",
    "\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim_out, dim_out)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def _build_projection(self,\n",
    "                          dim_in,\n",
    "                          dim_out,\n",
    "                          kernel_size,\n",
    "                          padding,\n",
    "                          stride,\n",
    "                          method):\n",
    "        if method == 'dw_bn':\n",
    "            proj = nn.Sequential(OrderedDict([\n",
    "                ('conv', nn.Conv2D(\n",
    "                    dim_in,\n",
    "                    dim_in,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=padding,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                    groups=dim_in\n",
    "                )),\n",
    "                ('bn', nn.BatchNorm2D(dim_in)),\n",
    "                ('rearrage', RearrangeLayer('b c h w -> b (h w) c')),\n",
    "            ]))\n",
    "        elif method == 'avg':\n",
    "            proj = nn.Sequential(OrderedDict([\n",
    "                ('avg', nn.AvgPool2D(\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=padding,\n",
    "                    stride=stride,\n",
    "                    ceil_mode=True\n",
    "                )),\n",
    "                ('rearrage', RearrangeLayer('b c h w -> b (h w) c')),\n",
    "            ]))\n",
    "        elif method == 'linear':\n",
    "            proj = None\n",
    "        else:\n",
    "            raise ValueError('Unknown method ({})'.format(method))\n",
    "\n",
    "        return proj\n",
    "\n",
    "    def forward_conv(self, x, h, w):\n",
    "        if self.with_cls_token: # spilt token from x\n",
    "            cls_token, x = paddle.split(x, [1, h*w], 1)\n",
    "\n",
    "        x =  PaddleRearrange(x, 'b (h w) c -> b c h w', h=h, w=w)\n",
    "\n",
    "        if self.conv_proj_q is not None:\n",
    "            q = self.conv_proj_q(x)\n",
    "        else:\n",
    "            q =  PaddleRearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "        if self.conv_proj_k is not None:\n",
    "            k = self.conv_proj_k(x)\n",
    "        else:\n",
    "            k =  PaddleRearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "        if self.conv_proj_v is not None:\n",
    "            v = self.conv_proj_v(x)\n",
    "        else:\n",
    "            v =  PaddleRearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "        if self.with_cls_token:\n",
    "            q = paddle.gather(cls_token, q, dim=1)\n",
    "            k = paddle.gather(cls_token, k, dim=1)\n",
    "            v = paddle.gather(cls_token, v, dim=1)\n",
    "\n",
    "        return q, k, v\n",
    "\n",
    "    def forward(self, x, h, w):\n",
    "        if (\n",
    "            self.conv_proj_q is not None\n",
    "            or self.conv_proj_k is not None\n",
    "            or self.conv_proj_v is not None\n",
    "        ):#if not generate q,k,v with Linear param\n",
    "            q, k, v = self.forward_conv(x, h, w)\n",
    "        #now q,k,v is b (h w) c\n",
    "        q =  PaddleRearrange(self.proj_q(q), 'b t (h d) -> b h t d', h=self.num_heads)#先扩宽token的维度，然后再实现mult-head，最后的结构是’b,h,t,d‘\n",
    "        k =  PaddleRearrange(self.proj_k(k), 'b t (h d) -> b h t d', h=self.num_heads)\n",
    "        v =  PaddleRearrange(self.proj_v(v), 'b t (h d) -> b h t d', h=self.num_heads)\n",
    "\n",
    "        attn_score = paddle.einsum('bhlk,bhtk->bhlt', [q, k]) * self.scale # 先按照axis=3乘，后*scale，实现q*k/sqort(d_k),\n",
    "        attn = nn.functional.softmax(attn_score, axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = paddle.einsum('bhlt,bhtv->bhlv', [attn, v]) # 将attention得到概率值与value信息值相乘得到结果，结构是，b,h,t,d\n",
    "        x =  PaddleRearrange(x, 'b h t d -> b t (h d)')\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "        return x#b,t,(h,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Layer):\n",
    "    ''' \n",
    "    每一个Block都是\n",
    "    token -> multihead attention ( reshape token to a grap) ->Mlp->token\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 dim_in,\n",
    "                 dim_out,\n",
    "                 num_heads,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 drop=0.,\n",
    "                 attn_drop=0.,\n",
    "                 drop_path=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.with_cls_token = kwargs['with_cls_token']\n",
    "\n",
    "        self.norm1 = norm_layer(dim_in)\n",
    "        self.attn = Attention(\n",
    "            dim_in, dim_out, num_heads, qkv_bias, attn_drop, drop,\n",
    "            **kwargs\n",
    "        )\n",
    "        if drop_path>0. :\n",
    "            self.drop_path=nn.Dropout(drop_path)\n",
    "        else:\n",
    "            self.drop_path=nn.Identity()\n",
    "        #self.drop_path = DropPath(drop_path) \\\n",
    "        #    if drop_path > 0. else nn.Identity()\n",
    "        \n",
    "        self.norm2 = norm_layer(dim_out)\n",
    "\n",
    "        dim_mlp_hidden = int(dim_out * mlp_ratio)\n",
    "        self.mlp = Mlp(\n",
    "            in_features=dim_out,\n",
    "            hidden_features=dim_mlp_hidden,\n",
    "            act_layer=act_layer,\n",
    "            drop=drop\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h, w):\n",
    "        res = x\n",
    "\n",
    "        x = self.norm1(x)\n",
    "        attn = self.attn(x, h, w)\n",
    "        x = res + self.drop_path(attn)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "输入是图片，输出是特征图和cls_token\n",
    "图片数据先经过ConvEmbed，得到一个特征图\n",
    "然后这个特征图会被reshape成token\n",
    "这个token会组合上cls_token，一起送入堆叠Block中，输出token\n",
    "最后会将这个token分离出cls_token和图片数据token，然后将图片数据reshape成图片数据的特征图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Layer):\n",
    "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 patch_size=16,\n",
    "                 patch_stride=16,\n",
    "                 patch_padding=0,\n",
    "                 in_chans=3,\n",
    "                 embed_dim=768,\n",
    "                 depth=12,\n",
    "                 num_heads=12,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 drop_rate=0.,\n",
    "                 attn_drop_rate=0.,\n",
    "                 drop_path_rate=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 init='trunc_norm',\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "\n",
    "        self.rearrage = None\n",
    "\n",
    "        self.patch_embed = ConvEmbed(\n",
    "            patch_size=patch_size,\n",
    "            in_chans=in_chans,\n",
    "            stride=patch_stride,\n",
    "            padding=patch_padding,\n",
    "            embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer\n",
    "        )\n",
    "\n",
    "        with_cls_token = kwargs['with_cls_token']\n",
    "        if with_cls_token:\n",
    "            self.cls_token=nn.initializer.TruncatedNormal(std=0.02)\n",
    "        else:\n",
    "            self.cls_token = None\n",
    "            \n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        dpr = [x.item() for x in paddle.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "\n",
    "        blocks = []\n",
    "        for j in range(depth):\n",
    "            blocks.append(\n",
    "                Block(\n",
    "                    dim_in=embed_dim,\n",
    "                    dim_out=embed_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    drop=drop_rate,\n",
    "                    attn_drop=attn_drop_rate,\n",
    "                    drop_path=dpr[j],\n",
    "                    act_layer=act_layer,\n",
    "                    norm_layer=norm_layer,\n",
    "                    **kwargs\n",
    "                )\n",
    "            )\n",
    "        self.blocks = nn.LayerList(blocks)\n",
    "\n",
    "        \n",
    "\n",
    "        if init == 'xavier':\n",
    "            self.apply(self._init_weights_xavier)\n",
    "        else:\n",
    "            self.apply(self._init_weights_trunc_normal)\n",
    "\n",
    "    def _init_weights_trunc_normal(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            logging.info('=> init weight of Linear from trunc norm')\n",
    "            m.weight=nn.initializer.TruncatedNormal(std=0.02)\n",
    "            if m.bias is not None:\n",
    "                logging.info('=> init bias of Linear to zeros')\n",
    "                m.bias=nn.initializer.Constant(0)\n",
    "        elif isinstance(m, (nn.LayerNorm, nn.BatchNorm2D)):\n",
    "            m.bias=nn.initializer.Constant(0)\n",
    "            m.weight=nn.initializer.Constant(1.0)\n",
    "\n",
    "    def _init_weights_xavier(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            logging.info('=> init weight of Linear from xavier uniform')\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                logging.info('=> init bias of Linear to zeros')\n",
    "                m.bias=nn.initializer.Constant(0)\n",
    "        elif isinstance(m, (nn.LayerNorm, nn.BatchNorm2D)):\n",
    "            m.bias=nn.initializer.Constant(0)\n",
    "            m.weight=nn.initializer.Constant(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        B, C, H, W = x.size()\n",
    "\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "        cls_tokens = None\n",
    "        if self.cls_token is not None:\n",
    "            # stole cls_tokens impl from Phil Wang, thanks\n",
    "            cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "            x = paddle.gather(cls_tokens, x, dim=1)\n",
    "\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            x = blk(x, H, W)\n",
    "\n",
    "        if self.cls_token is not None:\n",
    "            cls_tokens, x = paddle.split(x, [1, H*W], 1)\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=H, w=W)\n",
    "\n",
    "        return x, cls_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalVisionTransformer(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 in_chans=3,\n",
    "                 num_classes=1000,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 init='trunc_norm',\n",
    "                 spec=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.num_stages = spec['NUM_STAGES']\n",
    "        for i in range(self.num_stages):\n",
    "            kwargs = {\n",
    "                'patch_size': spec['PATCH_SIZE'][i],\n",
    "                'patch_stride': spec['PATCH_STRIDE'][i],\n",
    "                'patch_padding': spec['PATCH_PADDING'][i],\n",
    "                'embed_dim': spec['DIM_EMBED'][i],\n",
    "                'depth': spec['DEPTH'][i],\n",
    "                'num_heads': spec['NUM_HEADS'][i],\n",
    "                'mlp_ratio': spec['MLP_RATIO'][i],\n",
    "                'qkv_bias': spec['QKV_BIAS'][i],\n",
    "                'drop_rate': spec['DROP_RATE'][i],\n",
    "                'attn_drop_rate': spec['ATTN_DROP_RATE'][i],\n",
    "                'drop_path_rate': spec['DROP_PATH_RATE'][i],\n",
    "                'with_cls_token': spec['CLS_TOKEN'][i],\n",
    "                'method': spec['QKV_PROJ_METHOD'][i],\n",
    "                'kernel_size': spec['KERNEL_QKV'][i],\n",
    "                'padding_q': spec['PADDING_Q'][i],\n",
    "                'padding_kv': spec['PADDING_KV'][i],\n",
    "                'stride_kv': spec['STRIDE_KV'][i],\n",
    "                'stride_q': spec['STRIDE_Q'][i],\n",
    "            }\n",
    "\n",
    "            stage = VisionTransformer(\n",
    "                in_chans=in_chans,\n",
    "                init=init,\n",
    "                act_layer=act_layer,\n",
    "                norm_layer=norm_layer,\n",
    "                **kwargs\n",
    "            )\n",
    "            setattr(self, f'stage{i}', stage)\n",
    "\n",
    "            in_chans = spec['DIM_EMBED'][i]\n",
    "\n",
    "        dim_embed = spec['DIM_EMBED'][-1]\n",
    "        self.norm = norm_layer(dim_embed)\n",
    "        self.cls_token = spec['CLS_TOKEN'][-1]\n",
    "\n",
    "        # Classifier head\n",
    "        self.head = nn.Linear(dim_embed, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        self.head.weight=nn.initializer.TruncatedNormal(std=0.02)\n",
    "\n",
    "    def init_weights(self, pretrained='', pretrained_layers=[], verbose=True):\n",
    "        if os.path.isfile(pretrained):\n",
    "            pretrained_dict = paddle.load(pretrained, map_location='cpu')\n",
    "            logging.info(f'=> loading pretrained model {pretrained}')\n",
    "            model_dict = self.state_dict()\n",
    "            pretrained_dict = {\n",
    "                k: v for k, v in pretrained_dict.items()\n",
    "                if k in model_dict.keys()\n",
    "            }\n",
    "            need_init_state_dict = {}\n",
    "            for k, v in pretrained_dict.items():\n",
    "                need_init = (\n",
    "                        k.split('.')[0] in pretrained_layers\n",
    "                        or pretrained_layers[0] is '*'\n",
    "                )\n",
    "                if need_init:\n",
    "                    if verbose:\n",
    "                        logging.info(f'=> init {k} from {pretrained}')\n",
    "                    if 'pos_embed' in k and v.size() != model_dict[k].size():\n",
    "                        size_pretrained = v.size()\n",
    "                        size_new = model_dict[k].size()\n",
    "                        logging.info(\n",
    "                            '=> load_pretrained: resized variant: {} to {}'\n",
    "                            .format(size_pretrained, size_new)\n",
    "                        )\n",
    "\n",
    "                        ntok_new = size_new[1]\n",
    "                        ntok_new -= 1\n",
    "\n",
    "                        posemb_tok, posemb_grid = v[:, :1], v[0, 1:]\n",
    "\n",
    "                        gs_old = int(np.sqrt(len(posemb_grid)))\n",
    "                        gs_new = int(np.sqrt(ntok_new))\n",
    "\n",
    "                        logging.info(\n",
    "                            '=> load_pretrained: grid-size from {} to {}'\n",
    "                            .format(gs_old, gs_new)\n",
    "                        )\n",
    "\n",
    "                        posemb_grid = posemb_grid.reshape(gs_old, gs_old, -1)\n",
    "                        zoom = (gs_new / gs_old, gs_new / gs_old, 1)\n",
    "                        posemb_grid = paddle.ndimage.zoom(\n",
    "                            posemb_grid, zoom, order=1\n",
    "                        )\n",
    "                        posemb_grid = posemb_grid.reshape(1, gs_new ** 2, -1)\n",
    "                        v = paddle.to_tensor(\n",
    "                            np.concatenate([posemb_tok, posemb_grid], axis=1)\n",
    "                        )\n",
    "\n",
    "                    need_init_state_dict[k] = v\n",
    "            self.load_state_dict(need_init_state_dict, strict=False)\n",
    "    def forward_features(self, x):\n",
    "        for i in range(self.num_stages):\n",
    "            x, cls_tokens = getattr(self, f'stage{i}')(x)\n",
    "\n",
    "        if self.cls_token:\n",
    "            x = self.norm(cls_tokens)\n",
    "            x = paddle.squeeze(x)\n",
    "        else:\n",
    "            x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "            x = self.norm(x)\n",
    "            x = paddle.mean(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9648/987914161.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mConvolutionalVisionTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9648/1339407741.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_chans, num_classes, act_layer, norm_layer, init, spec)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_stages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NUM_STAGES'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             kwargs = {\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "x=ConvolutionalVisionTransformer()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "632b173250d16d6f9b5bd55f86a0e0c96b37a21df53bd488615da0bb1f86a5c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('cvt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
