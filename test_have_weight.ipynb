{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging config from ./config_cvt/config.yaml\n",
      "paddle:  Tensor(shape=[1, 1, 384], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[-0.00585411, -0.00050639,  0.01595476, -0.02997348,  0.00979930,\n",
      "          -0.00851270, -0.01875503,  0.02540751,  0.00602217, -0.00556154,\n",
      "           0.01083270,  0.02171696,  0.01596110,  0.02833709, -0.01525157,\n",
      "           0.02379513, -0.02391548, -0.00748633, -0.03510892,  0.03374053,\n",
      "          -0.01530699,  0.00631326, -0.01656432,  0.00156348, -0.01410553,\n",
      "           0.01601079,  0.02305610, -0.02584679, -0.01625600,  0.01157194,\n",
      "          -0.00455651, -0.00591906, -0.00770488, -0.01194432, -0.00002190,\n",
      "           0.01632214, -0.01688940,  0.00241593,  0.00780710,  0.02724976,\n",
      "          -0.00266871,  0.01129481, -0.00830469, -0.00936650,  0.02901398,\n",
      "          -0.00073761,  0.01376694,  0.00577840, -0.01892613,  0.00269733,\n",
      "           0.01031968,  0.03273948, -0.00194063, -0.01360198,  0.00593492,\n",
      "           0.03984804, -0.02444826, -0.01816158,  0.00028288, -0.00447109,\n",
      "           0.02583237,  0.02013904, -0.01422421, -0.02001531,  0.00114754,\n",
      "          -0.00408916, -0.02585659, -0.00278245,  0.02285705,  0.00931539,\n",
      "          -0.00943866,  0.01635865, -0.02847848, -0.01077647,  0.00592081,\n",
      "          -0.02096307, -0.00926997, -0.00926348,  0.01846910, -0.01342939,\n",
      "          -0.02713979,  0.00401422, -0.02775336,  0.03799995, -0.00353227,\n",
      "          -0.03155987,  0.02345335,  0.00379694,  0.00693890, -0.01501384,\n",
      "          -0.00652347,  0.02782342,  0.00271737, -0.00252375, -0.01212934,\n",
      "           0.01152373, -0.01972613,  0.00088790, -0.02627967,  0.02261269,\n",
      "          -0.00297240, -0.02160930,  0.02760352, -0.01313604, -0.00968422,\n",
      "           0.01526479, -0.02875779,  0.00842852,  0.00631509, -0.00963475,\n",
      "          -0.00134253,  0.01916127,  0.00938722,  0.00068248,  0.02501649,\n",
      "          -0.03031497, -0.00232266, -0.01489535, -0.01108825,  0.00902447,\n",
      "           0.00089210, -0.00735200,  0.01935206, -0.02067937, -0.00950014,\n",
      "           0.00624802, -0.02260882,  0.03200752,  0.00999879,  0.03340433,\n",
      "           0.02307072,  0.00876263, -0.01542857, -0.00555613, -0.01917960,\n",
      "          -0.02332060, -0.00824635,  0.01498634, -0.00255242, -0.02732603,\n",
      "          -0.00399480, -0.02931955,  0.01630155,  0.00711490,  0.00954425,\n",
      "           0.01959478, -0.01950070,  0.01788462,  0.02353407, -0.00006984,\n",
      "          -0.01673177, -0.00484656,  0.01208142,  0.00024924,  0.00173896,\n",
      "           0.01826382,  0.00586689,  0.00838020, -0.00220036, -0.03884020,\n",
      "           0.03231641,  0.00885409,  0.02849452, -0.00565827,  0.00238544,\n",
      "           0.00427168, -0.01301525, -0.03249300, -0.01889326, -0.02015597,\n",
      "           0.01086736, -0.01894499, -0.01326339, -0.01349871,  0.00521914,\n",
      "           0.01616776,  0.01446222, -0.00049863, -0.00830026,  0.02161231,\n",
      "          -0.00571633,  0.00584033, -0.02160906,  0.00579702, -0.01860115,\n",
      "          -0.01216040, -0.00286230,  0.00042650, -0.00020169, -0.01188998,\n",
      "           0.01922212,  0.00105384,  0.01879893,  0.00565546, -0.00318917,\n",
      "           0.01522608,  0.00340508,  0.01480846, -0.01349678,  0.00897057,\n",
      "           0.00889969, -0.00097622,  0.00330857, -0.00501028, -0.01678484,\n",
      "          -0.00640844, -0.02880808,  0.01374981, -0.02629408,  0.00498001,\n",
      "           0.02350579,  0.02294944, -0.02092526, -0.01973618,  0.00470554,\n",
      "           0.03102685,  0.02061141,  0.01176785, -0.02230881,  0.03674847,\n",
      "          -0.01278008, -0.02219213, -0.02229111,  0.00982964,  0.01337196,\n",
      "           0.00569844, -0.03492173,  0.01084787, -0.00710711, -0.02042788,\n",
      "           0.02784389, -0.00932526,  0.01292268,  0.03491581,  0.01854808,\n",
      "          -0.00530102, -0.01045481, -0.00020597, -0.00748740,  0.01147000,\n",
      "           0.02917709,  0.00254297,  0.02109439, -0.01553949,  0.01664474,\n",
      "           0.01223058, -0.00568868,  0.02193584, -0.01894800, -0.02242787,\n",
      "          -0.03379856,  0.01336831, -0.01028449, -0.00882872, -0.01878560,\n",
      "           0.00399770,  0.00897306, -0.02748417, -0.00706551,  0.00318401,\n",
      "          -0.03028212,  0.01131748,  0.02223458, -0.01860229,  0.00306550,\n",
      "          -0.01370572,  0.01728235, -0.01451350, -0.00593876, -0.02611073,\n",
      "           0.01747559,  0.00806732,  0.01405849,  0.01060522, -0.00617354,\n",
      "          -0.00371101,  0.01041795,  0.01461250,  0.00935151, -0.02113453,\n",
      "          -0.03032869, -0.00269972,  0.00534014, -0.01990516, -0.00342693,\n",
      "          -0.02948816,  0.01268756, -0.00096320, -0.01888165,  0.01012289,\n",
      "           0.03538364,  0.00358744,  0.01152964,  0.00944638,  0.01496292,\n",
      "           0.01915533, -0.02123853,  0.01101884, -0.02791542,  0.02026892,\n",
      "           0.00543127, -0.03228303, -0.01884134, -0.00170412,  0.00522326,\n",
      "          -0.00893035, -0.01634706,  0.00946622, -0.01316924, -0.01762016,\n",
      "           0.02117278,  0.01031729, -0.01988022, -0.03683249, -0.01775056,\n",
      "          -0.01753268, -0.01055137,  0.03144111, -0.03402417, -0.00414968,\n",
      "          -0.00880549,  0.00648677, -0.03057875, -0.02127163,  0.00356885,\n",
      "           0.00240258, -0.01878541,  0.01072608, -0.03438289,  0.01671704,\n",
      "           0.01443968,  0.01482671,  0.00526756,  0.00975607,  0.02391356,\n",
      "           0.01653704,  0.01747751,  0.00578472, -0.00851065, -0.00974540,\n",
      "          -0.01828066, -0.00949647,  0.03279265,  0.00979606, -0.01081984,\n",
      "           0.03068967, -0.02826539,  0.00139533,  0.00242563, -0.02832247,\n",
      "          -0.02236350,  0.00087722,  0.02608438, -0.02401756, -0.01162197,\n",
      "          -0.02436057,  0.01923670, -0.01601791,  0.02078255, -0.01352151,\n",
      "          -0.00517310, -0.02772429, -0.01701598, -0.01335970, -0.00391849,\n",
      "           0.02152281, -0.01597161,  0.00663104, -0.01743522,  0.00418649,\n",
      "           0.02871957, -0.00950239, -0.02328587,  0.02664825,  0.01613466,\n",
      "           0.00264724,  0.00312143, -0.02034595, -0.01613650,  0.02463715,\n",
      "           0.00045537, -0.03386302,  0.00423150,  0.02095152]]])\n",
      "------------------------\n",
      "None\n",
      "------------------------\n",
      "torch:  None\n",
      "------------------------\n",
      "None\n",
      "------------------------\n",
      "torch:  None\n",
      "------------------------\n",
      "Parameter containing:\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "       requires_grad=True)\n",
      "------------------------\n",
      "torch:  Parameter containing:\n",
      "tensor([[[ 0.0261, -0.0124,  0.0390, -0.0056,  0.0071, -0.0054, -0.0102,\n",
      "          -0.0106, -0.0049,  0.0037, -0.0151, -0.0209, -0.0031, -0.0127,\n",
      "          -0.0075,  0.0037,  0.0154,  0.0322,  0.0091, -0.0017,  0.0298,\n",
      "          -0.0030,  0.0049,  0.0354,  0.0310,  0.0139, -0.0095,  0.0214,\n",
      "          -0.0191,  0.0259, -0.0368,  0.0424,  0.0030,  0.0156, -0.0312,\n",
      "          -0.0048, -0.0252, -0.0392, -0.0162,  0.0064,  0.0156, -0.0122,\n",
      "           0.0227,  0.0216,  0.0265,  0.0096, -0.0209, -0.0360, -0.0226,\n",
      "          -0.0313,  0.0168, -0.0329, -0.0294, -0.0169, -0.0078, -0.0017,\n",
      "           0.0060, -0.0072, -0.0332, -0.0151,  0.0454,  0.0019,  0.0153,\n",
      "           0.0092,  0.0101, -0.0386, -0.0174, -0.0104,  0.0048,  0.0203,\n",
      "           0.0062,  0.0348,  0.0532,  0.0446,  0.0149,  0.0240,  0.0367,\n",
      "           0.0241,  0.0123, -0.0062,  0.0049, -0.0003,  0.0229,  0.0046,\n",
      "          -0.0101, -0.0070, -0.0269,  0.0554,  0.0072,  0.0069,  0.0257,\n",
      "          -0.0035,  0.0148,  0.0207,  0.0201, -0.0140, -0.0044,  0.0004,\n",
      "           0.0231,  0.0193, -0.0025,  0.0205, -0.0391,  0.0019,  0.0072,\n",
      "          -0.0187, -0.0212,  0.0481,  0.0094,  0.0415,  0.0320,  0.0254,\n",
      "          -0.0163,  0.0116, -0.0082,  0.0080, -0.0123,  0.0255, -0.0161,\n",
      "           0.0253,  0.0096,  0.0130, -0.0362, -0.0455, -0.0057, -0.0114,\n",
      "           0.0272,  0.0284,  0.0029,  0.0131,  0.0106, -0.0091,  0.0041,\n",
      "          -0.0060,  0.0189, -0.0021, -0.0425, -0.0216,  0.0681, -0.0186,\n",
      "           0.0357, -0.0086,  0.0042,  0.0436, -0.0043, -0.0215,  0.0083,\n",
      "           0.0263, -0.0108,  0.0046,  0.0012,  0.0062, -0.0088, -0.0564,\n",
      "          -0.0255, -0.0149, -0.0122,  0.0092,  0.0163, -0.0098, -0.0080,\n",
      "          -0.0256,  0.0066, -0.0044,  0.0390,  0.0009,  0.0021,  0.0160,\n",
      "          -0.0182, -0.0129, -0.0083,  0.0011, -0.0333,  0.0394,  0.0037,\n",
      "          -0.0017,  0.0076,  0.0016,  0.0057,  0.0182,  0.0264,  0.0260,\n",
      "          -0.0278,  0.0092,  0.0005, -0.0190,  0.0073, -0.0051,  0.0334,\n",
      "           0.0061,  0.0306, -0.0090,  0.0347,  0.0096,  0.0451,  0.0083,\n",
      "           0.0122,  0.0200, -0.0028,  0.0083, -0.0108, -0.0099, -0.0048,\n",
      "           0.0500,  0.0063,  0.0057,  0.0160, -0.0133, -0.0037, -0.0147,\n",
      "          -0.0036, -0.0115, -0.0173,  0.0249, -0.0008,  0.0282,  0.0106,\n",
      "           0.0161, -0.0343, -0.0178, -0.0209,  0.0016, -0.0085, -0.0499,\n",
      "           0.0054, -0.0037, -0.0116,  0.0018,  0.0139, -0.0040,  0.0254,\n",
      "          -0.0100, -0.0176, -0.0111, -0.0025, -0.0046,  0.0173, -0.0245,\n",
      "           0.0448, -0.0029,  0.0308, -0.0152, -0.0144,  0.0151, -0.0195,\n",
      "          -0.0242, -0.0115,  0.0355,  0.0158,  0.0126, -0.0195, -0.0050,\n",
      "           0.0129,  0.0077, -0.0112, -0.0115,  0.0222, -0.0114, -0.0112,\n",
      "          -0.0041, -0.0006, -0.0341, -0.0548, -0.0209,  0.0070, -0.0340,\n",
      "          -0.0169, -0.0019, -0.0024, -0.0246,  0.0365,  0.0167, -0.0177,\n",
      "          -0.0143,  0.0056,  0.0374,  0.0031, -0.0211, -0.0030, -0.0157,\n",
      "           0.0147,  0.0253,  0.0054,  0.0408,  0.0106,  0.0015,  0.0268,\n",
      "           0.0263, -0.0112,  0.0312,  0.0220,  0.0101,  0.0363,  0.0059,\n",
      "           0.0293, -0.0057,  0.0029, -0.0081, -0.0202,  0.0073, -0.0309,\n",
      "          -0.0141,  0.0053, -0.0045, -0.0077, -0.0051, -0.0205,  0.0100,\n",
      "           0.0014,  0.0016,  0.0276, -0.0015, -0.0054, -0.0171, -0.0281,\n",
      "           0.0135,  0.0015, -0.0046,  0.0060,  0.0322,  0.0186, -0.0090,\n",
      "           0.0281, -0.0148,  0.0207,  0.0199,  0.0155,  0.0079, -0.0188,\n",
      "          -0.0181, -0.0002, -0.0167,  0.0032,  0.0551,  0.0049,  0.0019,\n",
      "          -0.0209, -0.0167,  0.0498, -0.0048,  0.0027, -0.0174,  0.0019,\n",
      "           0.0002, -0.0420, -0.0018, -0.0644,  0.0009,  0.0189,  0.0367,\n",
      "           0.0310,  0.0183, -0.0227, -0.0091,  0.0043,  0.0168, -0.0096,\n",
      "           0.0040, -0.0043,  0.0245,  0.0216,  0.0224, -0.0306,  0.0072,\n",
      "           0.0286,  0.0217, -0.0081,  0.0257, -0.0100, -0.0259, -0.0083,\n",
      "           0.0128,  0.0171, -0.0205, -0.0003, -0.0211, -0.0073, -0.0022,\n",
      "           0.0267,  0.0271, -0.0027,  0.0128, -0.0045, -0.0306]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "import torch\n",
    "import os\n",
    "from config_cvt.default import get_config\n",
    "import torchvision.models as models\n",
    "from cvt import generate_model\n",
    "from cvt_torch import get_cls_model\n",
    "\n",
    "\n",
    "model_name = 'CvT-13-224x224-IN-1k.pth'\n",
    "\n",
    "config=get_config('./config_cvt/config.yaml')\n",
    "paddle.set_device('cpu')\n",
    "paddle_model = generate_model(config)\n",
    "paddle_model.eval()\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch_model= get_cls_model(config)\n",
    "torch_model.load_state_dict= torch.load(model_name,map_location=torch.device('cpu'))\n",
    "\n",
    "torch_model = torch_model.to(device)\n",
    "torch_model.eval()\n",
    "file_debug=open('debug.txt','w')\n",
    "\n",
    "x = np.random.randn(2, 3, 224, 224).astype('float32')\n",
    "x_paddle = paddle.to_tensor(x)\n",
    "x_torch = torch.Tensor(x)\n",
    "paddle.set_printoptions(4)\n",
    "torch.set_printoptions(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_to_paddle_mapping(torch_model,paddle_model):\n",
    "    paddle_array=[]\n",
    "    torch_array=[]\n",
    "    for i,value in torch_model.state_dict().items():\n",
    "        torch_array.append((i,value.shape))\n",
    "        #file_torch.write(str(tuple((i,value.shape))))\n",
    "        #file_torch.write('\\n')\n",
    "    for i,value in paddle_model.state_dict().items():\n",
    "        paddle_array.append((i,value.shape))\n",
    "        #file_paddle.write(str(tuple(((i,value.shape)))))\n",
    "        #file_paddle.write('\\n')\n",
    "    j=0\n",
    "    mapping=[]\n",
    "    mapping.append(('stage2.cls_token',  'stage2.cls_token'))\n",
    "    def equel(i,j):\n",
    "        x:str=torch_array[i][0]\n",
    "        y:str=paddle_array[j][0]\n",
    "        if x==y:\n",
    "            return True\n",
    "        x=x.replace('.bn.','.1.')\n",
    "        x=x.replace('.conv.','.0.')\n",
    "        x=x.replace('.running_mean','._mean')\n",
    "        x=x.replace('.running_var','._variance')\n",
    "        if x==y:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    for i in range(len(torch_array)):\n",
    "        if equel(i,j):\n",
    "            mapping.append((torch_array[i][0],paddle_array[j][0]))\n",
    "            j+=1\n",
    "    if len(mapping)!=len(paddle_array):\n",
    "        assert RuntimeError(f'mapping is not full,length of mapping is{len(mapping)},length of paddle_array is {len(paddle_array)}')\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(torch_model, paddle_model):\n",
    "    def _set_value(th_name, pd_name, transpose=True):\n",
    "        th_shape = th_params[th_name].shape\n",
    "        pd_shape = tuple(pd_params[pd_name].shape) \n",
    "        if isinstance(th_params[th_name], torch.nn.parameter.Parameter):\n",
    "            value = th_params[th_name].data.numpy()\n",
    "        else:\n",
    "            value = th_params[th_name].numpy()\n",
    "\n",
    "        if len(value.shape) == 2 and transpose:\n",
    "            value = value.transpose((1, 0))\n",
    "        pd_params[pd_name].set_value(value)\n",
    "\n",
    "    # 1. get paddle and torch model parameters\n",
    "    pd_params = {}\n",
    "    th_params = {}\n",
    "    for name, param in paddle_model.named_parameters():\n",
    "        pd_params[name] = param\n",
    "    for name, param in torch_model.named_parameters():\n",
    "        th_params[name] = param\n",
    "\n",
    "    for name, param in paddle_model.named_buffers():\n",
    "        pd_params[name] = param\n",
    "    for name, param in torch_model.named_buffers():\n",
    "        th_params[name] = param\n",
    "\n",
    "    # 2. get name mapping pairs\n",
    "    mapping = torch_to_paddle_mapping(torch_model,paddle_model)\n",
    "\n",
    "    # 3. set torch param values to paddle params: may needs transpose on weights\n",
    "    for th_name, pd_name in mapping:\n",
    "        if th_name in th_params.keys(): # nn.Parameters\n",
    "            _set_value(th_name, pd_name)\n",
    "        else: # weight & bias\n",
    "            th_name_w = f'{th_name}.weight'\n",
    "            pd_name_w = f'{pd_name}.weight'\n",
    "            _set_value(th_name_w, pd_name_w)\n",
    "\n",
    "            if f'{th_name}.bias' in th_params.keys():\n",
    "                th_name_b = f'{th_name}.bias'\n",
    "                pd_name_b = f'{pd_name}.bias'\n",
    "                _set_value(th_name_b, pd_name_b)\n",
    "\n",
    "    return paddle_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddle_model = convert(torch_model, paddle_model)\n",
    "out_torch = torch_model(x_torch)\n",
    "out_paddle = paddle_model(x_paddle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3779,  0.6164,  0.1666,  ...,  0.0830,  0.7966, -0.3871],\n",
       "        [ 0.2400,  0.5929,  0.1362,  ..., -0.0162,  0.3978, -0.2398]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 1000], dtype=float32, place=CPUPlace, stop_gradient=False,\n",
       "       [[-0.3779,  0.6164,  0.1666, ...,  0.0830,  0.7966, -0.3871],\n",
       "        [ 0.2400,  0.5929,  0.1362, ..., -0.0162,  0.3978, -0.2398]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'memoryview' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9580/3166297415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout_torch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mout_paddle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_paddle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile_debug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfile_debug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'memoryview' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "\n",
    "out_torch = out_torch.data.cpu().numpy()\n",
    "out_paddle = out_paddle.cpu().numpy()\n",
    "\n",
    "file_debug.write(str(out_torch.shape))\n",
    "file_debug.write('\\n')\n",
    "file_debug.write( str(out_paddle.shape))\n",
    "file_debug.write('\\n')\n",
    "file_debug.write(str(out_torch[0, 0:100]))\n",
    "file_debug.write('\\n')\n",
    "file_debug.write('========================================================')\n",
    "file_debug.write('\\n')\n",
    "file_debug.write(str(out_paddle[0, 0:100]))\n",
    "file_debug.write('\\n')\n",
    "\n",
    "assert np.allclose(out_torch, out_paddle, atol = 1e-2)\n",
    "\n",
    "# save weights for paddle model\n",
    "model_path = os.path.join(f'./{model_name}.pdparams')\n",
    "paddle.save(paddle_model.state_dict(), model_path)\n",
    "file_debug.write('all done')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "632b173250d16d6f9b5bd55f86a0e0c96b37a21df53bd488615da0bb1f86a5c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('cvt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
