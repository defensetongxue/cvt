{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging config from ./configs/cvt-13-224x224.yaml\n",
      "----------------------------------\n",
      "stage0.patch_embed.proj.weight [64, 3, 7, 7]\n",
      "stage0.patch_embed.proj.bias [64]\n",
      "stage0.patch_embed.norm.weight [64]\n",
      "stage0.patch_embed.norm.bias [64]\n",
      "stage0.blocks.0.norm1.weight [64]\n",
      "stage0.blocks.0.norm1.bias [64]\n",
      "stage0.blocks.0.attn.conv_proj_q.0.weight [64, 1, 3, 3]\n",
      "stage0.blocks.0.attn.conv_proj_q.1.weight [64]\n",
      "stage0.blocks.0.attn.conv_proj_q.1.bias [64]\n",
      "stage0.blocks.0.attn.conv_proj_q.1._mean [64]\n",
      "stage0.blocks.0.attn.conv_proj_q.1._variance [64]\n",
      "stage0.blocks.0.attn.conv_proj_k.0.weight [64, 1, 3, 3]\n",
      "stage0.blocks.0.attn.conv_proj_k.1.weight [64]\n",
      "stage0.blocks.0.attn.conv_proj_k.1.bias [64]\n",
      "stage0.blocks.0.attn.conv_proj_k.1._mean [64]\n",
      "stage0.blocks.0.attn.conv_proj_k.1._variance [64]\n",
      "stage0.blocks.0.attn.conv_proj_v.0.weight [64, 1, 3, 3]\n",
      "stage0.blocks.0.attn.conv_proj_v.1.weight [64]\n",
      "stage0.blocks.0.attn.conv_proj_v.1.bias [64]\n",
      "stage0.blocks.0.attn.conv_proj_v.1._mean [64]\n",
      "stage0.blocks.0.attn.conv_proj_v.1._variance [64]\n",
      "stage0.blocks.0.attn.proj_q.weight [64, 64]\n",
      "stage0.blocks.0.attn.proj_q.bias [64]\n",
      "stage0.blocks.0.attn.proj_k.weight [64, 64]\n",
      "stage0.blocks.0.attn.proj_k.bias [64]\n",
      "stage0.blocks.0.attn.proj_v.weight [64, 64]\n",
      "stage0.blocks.0.attn.proj_v.bias [64]\n",
      "stage0.blocks.0.attn.proj.weight [64, 64]\n",
      "stage0.blocks.0.attn.proj.bias [64]\n",
      "stage0.blocks.0.norm2.weight [64]\n",
      "stage0.blocks.0.norm2.bias [64]\n",
      "stage0.blocks.0.mlp.fc1.weight [64, 256]\n",
      "stage0.blocks.0.mlp.fc1.bias [256]\n",
      "stage0.blocks.0.mlp.fc2.weight [256, 64]\n",
      "stage0.blocks.0.mlp.fc2.bias [64]\n",
      "stage1.patch_embed.proj.weight [192, 64, 3, 3]\n",
      "stage1.patch_embed.proj.bias [192]\n",
      "stage1.patch_embed.norm.weight [192]\n",
      "stage1.patch_embed.norm.bias [192]\n",
      "stage1.blocks.0.norm1.weight [192]\n",
      "stage1.blocks.0.norm1.bias [192]\n",
      "stage1.blocks.0.attn.conv_proj_q.0.weight [192, 1, 3, 3]\n",
      "stage1.blocks.0.attn.conv_proj_q.1.weight [192]\n",
      "stage1.blocks.0.attn.conv_proj_q.1.bias [192]\n",
      "stage1.blocks.0.attn.conv_proj_q.1._mean [192]\n",
      "stage1.blocks.0.attn.conv_proj_q.1._variance [192]\n",
      "stage1.blocks.0.attn.conv_proj_k.0.weight [192, 1, 3, 3]\n",
      "stage1.blocks.0.attn.conv_proj_k.1.weight [192]\n",
      "stage1.blocks.0.attn.conv_proj_k.1.bias [192]\n",
      "stage1.blocks.0.attn.conv_proj_k.1._mean [192]\n",
      "stage1.blocks.0.attn.conv_proj_k.1._variance [192]\n",
      "stage1.blocks.0.attn.conv_proj_v.0.weight [192, 1, 3, 3]\n",
      "stage1.blocks.0.attn.conv_proj_v.1.weight [192]\n",
      "stage1.blocks.0.attn.conv_proj_v.1.bias [192]\n",
      "stage1.blocks.0.attn.conv_proj_v.1._mean [192]\n",
      "stage1.blocks.0.attn.conv_proj_v.1._variance [192]\n",
      "stage1.blocks.0.attn.proj_q.weight [192, 192]\n",
      "stage1.blocks.0.attn.proj_q.bias [192]\n",
      "stage1.blocks.0.attn.proj_k.weight [192, 192]\n",
      "stage1.blocks.0.attn.proj_k.bias [192]\n",
      "stage1.blocks.0.attn.proj_v.weight [192, 192]\n",
      "stage1.blocks.0.attn.proj_v.bias [192]\n",
      "stage1.blocks.0.attn.proj.weight [192, 192]\n",
      "stage1.blocks.0.attn.proj.bias [192]\n",
      "stage1.blocks.0.norm2.weight [192]\n",
      "stage1.blocks.0.norm2.bias [192]\n",
      "stage1.blocks.0.mlp.fc1.weight [192, 768]\n",
      "stage1.blocks.0.mlp.fc1.bias [768]\n",
      "stage1.blocks.0.mlp.fc2.weight [768, 192]\n",
      "stage1.blocks.0.mlp.fc2.bias [192]\n",
      "stage1.blocks.1.norm1.weight [192]\n",
      "stage1.blocks.1.norm1.bias [192]\n",
      "stage1.blocks.1.attn.conv_proj_q.0.weight [192, 1, 3, 3]\n",
      "stage1.blocks.1.attn.conv_proj_q.1.weight [192]\n",
      "stage1.blocks.1.attn.conv_proj_q.1.bias [192]\n",
      "stage1.blocks.1.attn.conv_proj_q.1._mean [192]\n",
      "stage1.blocks.1.attn.conv_proj_q.1._variance [192]\n",
      "stage1.blocks.1.attn.conv_proj_k.0.weight [192, 1, 3, 3]\n",
      "stage1.blocks.1.attn.conv_proj_k.1.weight [192]\n",
      "stage1.blocks.1.attn.conv_proj_k.1.bias [192]\n",
      "stage1.blocks.1.attn.conv_proj_k.1._mean [192]\n",
      "stage1.blocks.1.attn.conv_proj_k.1._variance [192]\n",
      "stage1.blocks.1.attn.conv_proj_v.0.weight [192, 1, 3, 3]\n",
      "stage1.blocks.1.attn.conv_proj_v.1.weight [192]\n",
      "stage1.blocks.1.attn.conv_proj_v.1.bias [192]\n",
      "stage1.blocks.1.attn.conv_proj_v.1._mean [192]\n",
      "stage1.blocks.1.attn.conv_proj_v.1._variance [192]\n",
      "stage1.blocks.1.attn.proj_q.weight [192, 192]\n",
      "stage1.blocks.1.attn.proj_q.bias [192]\n",
      "stage1.blocks.1.attn.proj_k.weight [192, 192]\n",
      "stage1.blocks.1.attn.proj_k.bias [192]\n",
      "stage1.blocks.1.attn.proj_v.weight [192, 192]\n",
      "stage1.blocks.1.attn.proj_v.bias [192]\n",
      "stage1.blocks.1.attn.proj.weight [192, 192]\n",
      "stage1.blocks.1.attn.proj.bias [192]\n",
      "stage1.blocks.1.norm2.weight [192]\n",
      "stage1.blocks.1.norm2.bias [192]\n",
      "stage1.blocks.1.mlp.fc1.weight [192, 768]\n",
      "stage1.blocks.1.mlp.fc1.bias [768]\n",
      "stage1.blocks.1.mlp.fc2.weight [768, 192]\n",
      "stage1.blocks.1.mlp.fc2.bias [192]\n",
      "stage2.cls_token [1, 1, 384]\n",
      "stage2.patch_embed.proj.weight [384, 192, 3, 3]\n",
      "stage2.patch_embed.proj.bias [384]\n",
      "stage2.patch_embed.norm.weight [384]\n",
      "stage2.patch_embed.norm.bias [384]\n",
      "stage2.blocks.0.norm1.weight [384]\n",
      "stage2.blocks.0.norm1.bias [384]\n",
      "stage2.blocks.0.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.0.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.0.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.0.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.0.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.0.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.0.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.0.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.0.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.0.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.0.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.0.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.0.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.0.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.0.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.0.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.0.attn.proj_q.bias [384]\n",
      "stage2.blocks.0.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.0.attn.proj_k.bias [384]\n",
      "stage2.blocks.0.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.0.attn.proj_v.bias [384]\n",
      "stage2.blocks.0.attn.proj.weight [384, 384]\n",
      "stage2.blocks.0.attn.proj.bias [384]\n",
      "stage2.blocks.0.norm2.weight [384]\n",
      "stage2.blocks.0.norm2.bias [384]\n",
      "stage2.blocks.0.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.0.mlp.fc1.bias [1536]\n",
      "stage2.blocks.0.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.0.mlp.fc2.bias [384]\n",
      "stage2.blocks.1.norm1.weight [384]\n",
      "stage2.blocks.1.norm1.bias [384]\n",
      "stage2.blocks.1.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.1.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.1.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.1.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.1.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.1.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.1.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.1.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.1.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.1.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.1.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.1.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.1.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.1.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.1.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.1.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.1.attn.proj_q.bias [384]\n",
      "stage2.blocks.1.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.1.attn.proj_k.bias [384]\n",
      "stage2.blocks.1.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.1.attn.proj_v.bias [384]\n",
      "stage2.blocks.1.attn.proj.weight [384, 384]\n",
      "stage2.blocks.1.attn.proj.bias [384]\n",
      "stage2.blocks.1.norm2.weight [384]\n",
      "stage2.blocks.1.norm2.bias [384]\n",
      "stage2.blocks.1.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.1.mlp.fc1.bias [1536]\n",
      "stage2.blocks.1.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.1.mlp.fc2.bias [384]\n",
      "stage2.blocks.2.norm1.weight [384]\n",
      "stage2.blocks.2.norm1.bias [384]\n",
      "stage2.blocks.2.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.2.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.2.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.2.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.2.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.2.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.2.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.2.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.2.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.2.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.2.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.2.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.2.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.2.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.2.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.2.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.2.attn.proj_q.bias [384]\n",
      "stage2.blocks.2.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.2.attn.proj_k.bias [384]\n",
      "stage2.blocks.2.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.2.attn.proj_v.bias [384]\n",
      "stage2.blocks.2.attn.proj.weight [384, 384]\n",
      "stage2.blocks.2.attn.proj.bias [384]\n",
      "stage2.blocks.2.norm2.weight [384]\n",
      "stage2.blocks.2.norm2.bias [384]\n",
      "stage2.blocks.2.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.2.mlp.fc1.bias [1536]\n",
      "stage2.blocks.2.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.2.mlp.fc2.bias [384]\n",
      "stage2.blocks.3.norm1.weight [384]\n",
      "stage2.blocks.3.norm1.bias [384]\n",
      "stage2.blocks.3.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.3.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.3.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.3.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.3.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.3.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.3.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.3.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.3.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.3.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.3.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.3.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.3.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.3.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.3.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.3.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.3.attn.proj_q.bias [384]\n",
      "stage2.blocks.3.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.3.attn.proj_k.bias [384]\n",
      "stage2.blocks.3.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.3.attn.proj_v.bias [384]\n",
      "stage2.blocks.3.attn.proj.weight [384, 384]\n",
      "stage2.blocks.3.attn.proj.bias [384]\n",
      "stage2.blocks.3.norm2.weight [384]\n",
      "stage2.blocks.3.norm2.bias [384]\n",
      "stage2.blocks.3.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.3.mlp.fc1.bias [1536]\n",
      "stage2.blocks.3.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.3.mlp.fc2.bias [384]\n",
      "stage2.blocks.4.norm1.weight [384]\n",
      "stage2.blocks.4.norm1.bias [384]\n",
      "stage2.blocks.4.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.4.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.4.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.4.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.4.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.4.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.4.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.4.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.4.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.4.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.4.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.4.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.4.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.4.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.4.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.4.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.4.attn.proj_q.bias [384]\n",
      "stage2.blocks.4.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.4.attn.proj_k.bias [384]\n",
      "stage2.blocks.4.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.4.attn.proj_v.bias [384]\n",
      "stage2.blocks.4.attn.proj.weight [384, 384]\n",
      "stage2.blocks.4.attn.proj.bias [384]\n",
      "stage2.blocks.4.norm2.weight [384]\n",
      "stage2.blocks.4.norm2.bias [384]\n",
      "stage2.blocks.4.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.4.mlp.fc1.bias [1536]\n",
      "stage2.blocks.4.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.4.mlp.fc2.bias [384]\n",
      "stage2.blocks.5.norm1.weight [384]\n",
      "stage2.blocks.5.norm1.bias [384]\n",
      "stage2.blocks.5.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.5.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.5.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.5.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.5.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.5.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.5.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.5.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.5.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.5.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.5.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.5.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.5.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.5.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.5.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.5.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.5.attn.proj_q.bias [384]\n",
      "stage2.blocks.5.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.5.attn.proj_k.bias [384]\n",
      "stage2.blocks.5.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.5.attn.proj_v.bias [384]\n",
      "stage2.blocks.5.attn.proj.weight [384, 384]\n",
      "stage2.blocks.5.attn.proj.bias [384]\n",
      "stage2.blocks.5.norm2.weight [384]\n",
      "stage2.blocks.5.norm2.bias [384]\n",
      "stage2.blocks.5.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.5.mlp.fc1.bias [1536]\n",
      "stage2.blocks.5.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.5.mlp.fc2.bias [384]\n",
      "stage2.blocks.6.norm1.weight [384]\n",
      "stage2.blocks.6.norm1.bias [384]\n",
      "stage2.blocks.6.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.6.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.6.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.6.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.6.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.6.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.6.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.6.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.6.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.6.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.6.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.6.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.6.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.6.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.6.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.6.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.6.attn.proj_q.bias [384]\n",
      "stage2.blocks.6.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.6.attn.proj_k.bias [384]\n",
      "stage2.blocks.6.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.6.attn.proj_v.bias [384]\n",
      "stage2.blocks.6.attn.proj.weight [384, 384]\n",
      "stage2.blocks.6.attn.proj.bias [384]\n",
      "stage2.blocks.6.norm2.weight [384]\n",
      "stage2.blocks.6.norm2.bias [384]\n",
      "stage2.blocks.6.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.6.mlp.fc1.bias [1536]\n",
      "stage2.blocks.6.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.6.mlp.fc2.bias [384]\n",
      "stage2.blocks.7.norm1.weight [384]\n",
      "stage2.blocks.7.norm1.bias [384]\n",
      "stage2.blocks.7.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.7.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.7.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.7.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.7.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.7.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.7.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.7.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.7.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.7.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.7.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.7.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.7.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.7.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.7.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.7.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.7.attn.proj_q.bias [384]\n",
      "stage2.blocks.7.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.7.attn.proj_k.bias [384]\n",
      "stage2.blocks.7.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.7.attn.proj_v.bias [384]\n",
      "stage2.blocks.7.attn.proj.weight [384, 384]\n",
      "stage2.blocks.7.attn.proj.bias [384]\n",
      "stage2.blocks.7.norm2.weight [384]\n",
      "stage2.blocks.7.norm2.bias [384]\n",
      "stage2.blocks.7.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.7.mlp.fc1.bias [1536]\n",
      "stage2.blocks.7.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.7.mlp.fc2.bias [384]\n",
      "stage2.blocks.8.norm1.weight [384]\n",
      "stage2.blocks.8.norm1.bias [384]\n",
      "stage2.blocks.8.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.8.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.8.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.8.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.8.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.8.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.8.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.8.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.8.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.8.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.8.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.8.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.8.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.8.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.8.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.8.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.8.attn.proj_q.bias [384]\n",
      "stage2.blocks.8.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.8.attn.proj_k.bias [384]\n",
      "stage2.blocks.8.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.8.attn.proj_v.bias [384]\n",
      "stage2.blocks.8.attn.proj.weight [384, 384]\n",
      "stage2.blocks.8.attn.proj.bias [384]\n",
      "stage2.blocks.8.norm2.weight [384]\n",
      "stage2.blocks.8.norm2.bias [384]\n",
      "stage2.blocks.8.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.8.mlp.fc1.bias [1536]\n",
      "stage2.blocks.8.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.8.mlp.fc2.bias [384]\n",
      "stage2.blocks.9.norm1.weight [384]\n",
      "stage2.blocks.9.norm1.bias [384]\n",
      "stage2.blocks.9.attn.conv_proj_q.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.9.attn.conv_proj_q.1.weight [384]\n",
      "stage2.blocks.9.attn.conv_proj_q.1.bias [384]\n",
      "stage2.blocks.9.attn.conv_proj_q.1._mean [384]\n",
      "stage2.blocks.9.attn.conv_proj_q.1._variance [384]\n",
      "stage2.blocks.9.attn.conv_proj_k.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.9.attn.conv_proj_k.1.weight [384]\n",
      "stage2.blocks.9.attn.conv_proj_k.1.bias [384]\n",
      "stage2.blocks.9.attn.conv_proj_k.1._mean [384]\n",
      "stage2.blocks.9.attn.conv_proj_k.1._variance [384]\n",
      "stage2.blocks.9.attn.conv_proj_v.0.weight [384, 1, 3, 3]\n",
      "stage2.blocks.9.attn.conv_proj_v.1.weight [384]\n",
      "stage2.blocks.9.attn.conv_proj_v.1.bias [384]\n",
      "stage2.blocks.9.attn.conv_proj_v.1._mean [384]\n",
      "stage2.blocks.9.attn.conv_proj_v.1._variance [384]\n",
      "stage2.blocks.9.attn.proj_q.weight [384, 384]\n",
      "stage2.blocks.9.attn.proj_q.bias [384]\n",
      "stage2.blocks.9.attn.proj_k.weight [384, 384]\n",
      "stage2.blocks.9.attn.proj_k.bias [384]\n",
      "stage2.blocks.9.attn.proj_v.weight [384, 384]\n",
      "stage2.blocks.9.attn.proj_v.bias [384]\n",
      "stage2.blocks.9.attn.proj.weight [384, 384]\n",
      "stage2.blocks.9.attn.proj.bias [384]\n",
      "stage2.blocks.9.norm2.weight [384]\n",
      "stage2.blocks.9.norm2.bias [384]\n",
      "stage2.blocks.9.mlp.fc1.weight [384, 1536]\n",
      "stage2.blocks.9.mlp.fc1.bias [1536]\n",
      "stage2.blocks.9.mlp.fc2.weight [1536, 384]\n",
      "stage2.blocks.9.mlp.fc2.bias [384]\n",
      "norm.weight [384]\n",
      "norm.bias [384]\n",
      "head.weight [384, 1000]\n",
      "head.bias [1000]\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "=> merge config from ./cvt_torch/cvt-13-224x224.yaml\n",
      "----------------------------------\n",
      "stage0.patch_embed.proj.weight torch.Size([64, 3, 7, 7])\n",
      "stage0.patch_embed.proj.bias torch.Size([64])\n",
      "stage0.patch_embed.norm.weight torch.Size([64])\n",
      "stage0.patch_embed.norm.bias torch.Size([64])\n",
      "stage0.blocks.0.norm1.weight torch.Size([64])\n",
      "stage0.blocks.0.norm1.bias torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_q.conv.weight torch.Size([64, 1, 3, 3])\n",
      "stage0.blocks.0.attn.conv_proj_q.bn.weight torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_q.bn.bias torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_k.conv.weight torch.Size([64, 1, 3, 3])\n",
      "stage0.blocks.0.attn.conv_proj_k.bn.weight torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_k.bn.bias torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_v.conv.weight torch.Size([64, 1, 3, 3])\n",
      "stage0.blocks.0.attn.conv_proj_v.bn.weight torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_v.bn.bias torch.Size([64])\n",
      "stage0.blocks.0.attn.proj_q.weight torch.Size([64, 64])\n",
      "stage0.blocks.0.attn.proj_q.bias torch.Size([64])\n",
      "stage0.blocks.0.attn.proj_k.weight torch.Size([64, 64])\n",
      "stage0.blocks.0.attn.proj_k.bias torch.Size([64])\n",
      "stage0.blocks.0.attn.proj_v.weight torch.Size([64, 64])\n",
      "stage0.blocks.0.attn.proj_v.bias torch.Size([64])\n",
      "stage0.blocks.0.attn.proj.weight torch.Size([64, 64])\n",
      "stage0.blocks.0.attn.proj.bias torch.Size([64])\n",
      "stage0.blocks.0.norm2.weight torch.Size([64])\n",
      "stage0.blocks.0.norm2.bias torch.Size([64])\n",
      "stage0.blocks.0.mlp.fc1.weight torch.Size([256, 64])\n",
      "stage0.blocks.0.mlp.fc1.bias torch.Size([256])\n",
      "stage0.blocks.0.mlp.fc2.weight torch.Size([64, 256])\n",
      "stage0.blocks.0.mlp.fc2.bias torch.Size([64])\n",
      "stage1.patch_embed.proj.weight torch.Size([192, 64, 3, 3])\n",
      "stage1.patch_embed.proj.bias torch.Size([192])\n",
      "stage1.patch_embed.norm.weight torch.Size([192])\n",
      "stage1.patch_embed.norm.bias torch.Size([192])\n",
      "stage1.blocks.0.norm1.weight torch.Size([192])\n",
      "stage1.blocks.0.norm1.bias torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_q.conv.weight torch.Size([192, 1, 3, 3])\n",
      "stage1.blocks.0.attn.conv_proj_q.bn.weight torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_q.bn.bias torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_k.conv.weight torch.Size([192, 1, 3, 3])\n",
      "stage1.blocks.0.attn.conv_proj_k.bn.weight torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_k.bn.bias torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_v.conv.weight torch.Size([192, 1, 3, 3])\n",
      "stage1.blocks.0.attn.conv_proj_v.bn.weight torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_v.bn.bias torch.Size([192])\n",
      "stage1.blocks.0.attn.proj_q.weight torch.Size([192, 192])\n",
      "stage1.blocks.0.attn.proj_q.bias torch.Size([192])\n",
      "stage1.blocks.0.attn.proj_k.weight torch.Size([192, 192])\n",
      "stage1.blocks.0.attn.proj_k.bias torch.Size([192])\n",
      "stage1.blocks.0.attn.proj_v.weight torch.Size([192, 192])\n",
      "stage1.blocks.0.attn.proj_v.bias torch.Size([192])\n",
      "stage1.blocks.0.attn.proj.weight torch.Size([192, 192])\n",
      "stage1.blocks.0.attn.proj.bias torch.Size([192])\n",
      "stage1.blocks.0.norm2.weight torch.Size([192])\n",
      "stage1.blocks.0.norm2.bias torch.Size([192])\n",
      "stage1.blocks.0.mlp.fc1.weight torch.Size([768, 192])\n",
      "stage1.blocks.0.mlp.fc1.bias torch.Size([768])\n",
      "stage1.blocks.0.mlp.fc2.weight torch.Size([192, 768])\n",
      "stage1.blocks.0.mlp.fc2.bias torch.Size([192])\n",
      "stage1.blocks.1.norm1.weight torch.Size([192])\n",
      "stage1.blocks.1.norm1.bias torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_q.conv.weight torch.Size([192, 1, 3, 3])\n",
      "stage1.blocks.1.attn.conv_proj_q.bn.weight torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_q.bn.bias torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_k.conv.weight torch.Size([192, 1, 3, 3])\n",
      "stage1.blocks.1.attn.conv_proj_k.bn.weight torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_k.bn.bias torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_v.conv.weight torch.Size([192, 1, 3, 3])\n",
      "stage1.blocks.1.attn.conv_proj_v.bn.weight torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_v.bn.bias torch.Size([192])\n",
      "stage1.blocks.1.attn.proj_q.weight torch.Size([192, 192])\n",
      "stage1.blocks.1.attn.proj_q.bias torch.Size([192])\n",
      "stage1.blocks.1.attn.proj_k.weight torch.Size([192, 192])\n",
      "stage1.blocks.1.attn.proj_k.bias torch.Size([192])\n",
      "stage1.blocks.1.attn.proj_v.weight torch.Size([192, 192])\n",
      "stage1.blocks.1.attn.proj_v.bias torch.Size([192])\n",
      "stage1.blocks.1.attn.proj.weight torch.Size([192, 192])\n",
      "stage1.blocks.1.attn.proj.bias torch.Size([192])\n",
      "stage1.blocks.1.norm2.weight torch.Size([192])\n",
      "stage1.blocks.1.norm2.bias torch.Size([192])\n",
      "stage1.blocks.1.mlp.fc1.weight torch.Size([768, 192])\n",
      "stage1.blocks.1.mlp.fc1.bias torch.Size([768])\n",
      "stage1.blocks.1.mlp.fc2.weight torch.Size([192, 768])\n",
      "stage1.blocks.1.mlp.fc2.bias torch.Size([192])\n",
      "stage2.cls_token torch.Size([1, 1, 384])\n",
      "stage2.patch_embed.proj.weight torch.Size([384, 192, 3, 3])\n",
      "stage2.patch_embed.proj.bias torch.Size([384])\n",
      "stage2.patch_embed.norm.weight torch.Size([384])\n",
      "stage2.patch_embed.norm.bias torch.Size([384])\n",
      "stage2.blocks.0.norm1.weight torch.Size([384])\n",
      "stage2.blocks.0.norm1.bias torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.0.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.0.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.0.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.0.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.0.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.0.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.0.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.0.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.0.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.0.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.0.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.0.norm2.weight torch.Size([384])\n",
      "stage2.blocks.0.norm2.bias torch.Size([384])\n",
      "stage2.blocks.0.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.0.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.0.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.0.mlp.fc2.bias torch.Size([384])\n",
      "stage2.blocks.1.norm1.weight torch.Size([384])\n",
      "stage2.blocks.1.norm1.bias torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.1.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.1.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.1.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.1.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.1.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.1.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.1.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.1.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.1.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.1.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.1.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.1.norm2.weight torch.Size([384])\n",
      "stage2.blocks.1.norm2.bias torch.Size([384])\n",
      "stage2.blocks.1.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.1.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.1.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.1.mlp.fc2.bias torch.Size([384])\n",
      "stage2.blocks.2.norm1.weight torch.Size([384])\n",
      "stage2.blocks.2.norm1.bias torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.2.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.2.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.2.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.2.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.2.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.2.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.2.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.2.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.2.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.2.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.2.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.2.norm2.weight torch.Size([384])\n",
      "stage2.blocks.2.norm2.bias torch.Size([384])\n",
      "stage2.blocks.2.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.2.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.2.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.2.mlp.fc2.bias torch.Size([384])\n",
      "stage2.blocks.3.norm1.weight torch.Size([384])\n",
      "stage2.blocks.3.norm1.bias torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.3.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.3.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.3.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.3.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.3.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.3.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.3.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.3.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.3.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.3.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.3.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.3.norm2.weight torch.Size([384])\n",
      "stage2.blocks.3.norm2.bias torch.Size([384])\n",
      "stage2.blocks.3.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.3.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.3.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.3.mlp.fc2.bias torch.Size([384])\n",
      "stage2.blocks.4.norm1.weight torch.Size([384])\n",
      "stage2.blocks.4.norm1.bias torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.4.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.4.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.4.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.4.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.4.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.4.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.4.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.4.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.4.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.4.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.4.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.4.norm2.weight torch.Size([384])\n",
      "stage2.blocks.4.norm2.bias torch.Size([384])\n",
      "stage2.blocks.4.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.4.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.4.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.4.mlp.fc2.bias torch.Size([384])\n",
      "stage2.blocks.5.norm1.weight torch.Size([384])\n",
      "stage2.blocks.5.norm1.bias torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.5.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.5.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.5.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.5.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.5.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.5.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.5.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.5.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.5.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.5.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.5.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.5.norm2.weight torch.Size([384])\n",
      "stage2.blocks.5.norm2.bias torch.Size([384])\n",
      "stage2.blocks.5.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.5.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.5.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.5.mlp.fc2.bias torch.Size([384])\n",
      "stage2.blocks.6.norm1.weight torch.Size([384])\n",
      "stage2.blocks.6.norm1.bias torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.6.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.6.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.6.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.6.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.6.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.6.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.6.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.6.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.6.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.6.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.6.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.6.norm2.weight torch.Size([384])\n",
      "stage2.blocks.6.norm2.bias torch.Size([384])\n",
      "stage2.blocks.6.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.6.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.6.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.6.mlp.fc2.bias torch.Size([384])\n",
      "stage2.blocks.7.norm1.weight torch.Size([384])\n",
      "stage2.blocks.7.norm1.bias torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.7.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.7.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.7.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.7.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.7.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.7.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.7.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.7.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.7.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.7.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.7.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.7.norm2.weight torch.Size([384])\n",
      "stage2.blocks.7.norm2.bias torch.Size([384])\n",
      "stage2.blocks.7.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.7.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.7.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.7.mlp.fc2.bias torch.Size([384])\n",
      "stage2.blocks.8.norm1.weight torch.Size([384])\n",
      "stage2.blocks.8.norm1.bias torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.8.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.8.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.8.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.8.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.8.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.8.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.8.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.8.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.8.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.8.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.8.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.8.norm2.weight torch.Size([384])\n",
      "stage2.blocks.8.norm2.bias torch.Size([384])\n",
      "stage2.blocks.8.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.8.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.8.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.8.mlp.fc2.bias torch.Size([384])\n",
      "stage2.blocks.9.norm1.weight torch.Size([384])\n",
      "stage2.blocks.9.norm1.bias torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.9.attn.conv_proj_q.bn.weight torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_q.bn.bias torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.9.attn.conv_proj_k.bn.weight torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_k.bn.bias torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3])\n",
      "stage2.blocks.9.attn.conv_proj_v.bn.weight torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_v.bn.bias torch.Size([384])\n",
      "stage2.blocks.9.attn.proj_q.weight torch.Size([384, 384])\n",
      "stage2.blocks.9.attn.proj_q.bias torch.Size([384])\n",
      "stage2.blocks.9.attn.proj_k.weight torch.Size([384, 384])\n",
      "stage2.blocks.9.attn.proj_k.bias torch.Size([384])\n",
      "stage2.blocks.9.attn.proj_v.weight torch.Size([384, 384])\n",
      "stage2.blocks.9.attn.proj_v.bias torch.Size([384])\n",
      "stage2.blocks.9.attn.proj.weight torch.Size([384, 384])\n",
      "stage2.blocks.9.attn.proj.bias torch.Size([384])\n",
      "stage2.blocks.9.norm2.weight torch.Size([384])\n",
      "stage2.blocks.9.norm2.bias torch.Size([384])\n",
      "stage2.blocks.9.mlp.fc1.weight torch.Size([1536, 384])\n",
      "stage2.blocks.9.mlp.fc1.bias torch.Size([1536])\n",
      "stage2.blocks.9.mlp.fc2.weight torch.Size([384, 1536])\n",
      "stage2.blocks.9.mlp.fc2.bias torch.Size([384])\n",
      "norm.weight torch.Size([384])\n",
      "norm.bias torch.Size([384])\n",
      "head.weight torch.Size([1000, 384])\n",
      "head.bias torch.Size([1000])\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "stage0.blocks.0.attn.conv_proj_q.bn.running_mean torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_q.bn.running_var torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage0.blocks.0.attn.conv_proj_k.bn.running_mean torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_k.bn.running_var torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage0.blocks.0.attn.conv_proj_v.bn.running_mean torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_v.bn.running_var torch.Size([64])\n",
      "stage0.blocks.0.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage1.blocks.0.attn.conv_proj_q.bn.running_mean torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_q.bn.running_var torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage1.blocks.0.attn.conv_proj_k.bn.running_mean torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_k.bn.running_var torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage1.blocks.0.attn.conv_proj_v.bn.running_mean torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_v.bn.running_var torch.Size([192])\n",
      "stage1.blocks.0.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage1.blocks.1.attn.conv_proj_q.bn.running_mean torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_q.bn.running_var torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage1.blocks.1.attn.conv_proj_k.bn.running_mean torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_k.bn.running_var torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage1.blocks.1.attn.conv_proj_v.bn.running_mean torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_v.bn.running_var torch.Size([192])\n",
      "stage1.blocks.1.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.0.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.0.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.0.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.0.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.1.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.1.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.1.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.1.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.2.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.2.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.2.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.2.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.3.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.3.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.3.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.3.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.4.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.4.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.4.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.4.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.5.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.5.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.5.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.5.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.6.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.6.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.6.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.6.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.7.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.7.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.7.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.7.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.8.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.8.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.8.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.8.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.9.attn.conv_proj_q.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_q.bn.running_var torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_q.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.9.attn.conv_proj_k.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_k.bn.running_var torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_k.bn.num_batches_tracked torch.Size([])\n",
      "stage2.blocks.9.attn.conv_proj_v.bn.running_mean torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_v.bn.running_var torch.Size([384])\n",
      "stage2.blocks.9.attn.conv_proj_v.bn.num_batches_tracked torch.Size([])\n",
      "----------------------------------\n",
      "set stage2.cls_token torch.Size([1, 1, 384]) to stage2.cls_token (1, 1, 384)\n",
      "set stage0.patch_embed.proj.weight torch.Size([64, 3, 7, 7]) to stage0.patch_embed.proj.weight (64, 3, 7, 7)\n",
      "set stage0.patch_embed.proj.bias torch.Size([64]) to stage0.patch_embed.proj.bias (64,)\n",
      "set stage0.patch_embed.norm.weight torch.Size([64]) to stage0.patch_embed.norm.weight (64,)\n",
      "set stage0.patch_embed.norm.bias torch.Size([64]) to stage0.patch_embed.norm.bias (64,)\n",
      "set stage0.blocks.0.norm1.weight torch.Size([64]) to stage0.blocks.0.norm1.weight (64,)\n",
      "set stage0.blocks.0.norm1.bias torch.Size([64]) to stage0.blocks.0.norm1.bias (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_q.conv.weight torch.Size([64, 1, 3, 3]) to stage0.blocks.0.attn.conv_proj_q.0.weight (64, 1, 3, 3)\n",
      "set stage0.blocks.0.attn.conv_proj_q.bn.weight torch.Size([64]) to stage0.blocks.0.attn.conv_proj_q.1.weight (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_q.bn.bias torch.Size([64]) to stage0.blocks.0.attn.conv_proj_q.1.bias (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_q.bn.running_mean torch.Size([64]) to stage0.blocks.0.attn.conv_proj_q.1._mean (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_q.bn.running_var torch.Size([64]) to stage0.blocks.0.attn.conv_proj_q.1._variance (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_k.conv.weight torch.Size([64, 1, 3, 3]) to stage0.blocks.0.attn.conv_proj_k.0.weight (64, 1, 3, 3)\n",
      "set stage0.blocks.0.attn.conv_proj_k.bn.weight torch.Size([64]) to stage0.blocks.0.attn.conv_proj_k.1.weight (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_k.bn.bias torch.Size([64]) to stage0.blocks.0.attn.conv_proj_k.1.bias (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_k.bn.running_mean torch.Size([64]) to stage0.blocks.0.attn.conv_proj_k.1._mean (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_k.bn.running_var torch.Size([64]) to stage0.blocks.0.attn.conv_proj_k.1._variance (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_v.conv.weight torch.Size([64, 1, 3, 3]) to stage0.blocks.0.attn.conv_proj_v.0.weight (64, 1, 3, 3)\n",
      "set stage0.blocks.0.attn.conv_proj_v.bn.weight torch.Size([64]) to stage0.blocks.0.attn.conv_proj_v.1.weight (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_v.bn.bias torch.Size([64]) to stage0.blocks.0.attn.conv_proj_v.1.bias (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_v.bn.running_mean torch.Size([64]) to stage0.blocks.0.attn.conv_proj_v.1._mean (64,)\n",
      "set stage0.blocks.0.attn.conv_proj_v.bn.running_var torch.Size([64]) to stage0.blocks.0.attn.conv_proj_v.1._variance (64,)\n",
      "set stage0.blocks.0.attn.proj_q.weight torch.Size([64, 64]) to stage0.blocks.0.attn.proj_q.weight (64, 64)\n",
      "set stage0.blocks.0.attn.proj_q.bias torch.Size([64]) to stage0.blocks.0.attn.proj_q.bias (64,)\n",
      "set stage0.blocks.0.attn.proj_k.weight torch.Size([64, 64]) to stage0.blocks.0.attn.proj_k.weight (64, 64)\n",
      "set stage0.blocks.0.attn.proj_k.bias torch.Size([64]) to stage0.blocks.0.attn.proj_k.bias (64,)\n",
      "set stage0.blocks.0.attn.proj_v.weight torch.Size([64, 64]) to stage0.blocks.0.attn.proj_v.weight (64, 64)\n",
      "set stage0.blocks.0.attn.proj_v.bias torch.Size([64]) to stage0.blocks.0.attn.proj_v.bias (64,)\n",
      "set stage0.blocks.0.attn.proj.weight torch.Size([64, 64]) to stage0.blocks.0.attn.proj.weight (64, 64)\n",
      "set stage0.blocks.0.attn.proj.bias torch.Size([64]) to stage0.blocks.0.attn.proj.bias (64,)\n",
      "set stage0.blocks.0.norm2.weight torch.Size([64]) to stage0.blocks.0.norm2.weight (64,)\n",
      "set stage0.blocks.0.norm2.bias torch.Size([64]) to stage0.blocks.0.norm2.bias (64,)\n",
      "set stage0.blocks.0.mlp.fc1.weight torch.Size([256, 64]) to stage0.blocks.0.mlp.fc1.weight (64, 256)\n",
      "set stage0.blocks.0.mlp.fc1.bias torch.Size([256]) to stage0.blocks.0.mlp.fc1.bias (256,)\n",
      "set stage0.blocks.0.mlp.fc2.weight torch.Size([64, 256]) to stage0.blocks.0.mlp.fc2.weight (256, 64)\n",
      "set stage0.blocks.0.mlp.fc2.bias torch.Size([64]) to stage0.blocks.0.mlp.fc2.bias (64,)\n",
      "set stage1.patch_embed.proj.weight torch.Size([192, 64, 3, 3]) to stage1.patch_embed.proj.weight (192, 64, 3, 3)\n",
      "set stage1.patch_embed.proj.bias torch.Size([192]) to stage1.patch_embed.proj.bias (192,)\n",
      "set stage1.patch_embed.norm.weight torch.Size([192]) to stage1.patch_embed.norm.weight (192,)\n",
      "set stage1.patch_embed.norm.bias torch.Size([192]) to stage1.patch_embed.norm.bias (192,)\n",
      "set stage1.blocks.0.norm1.weight torch.Size([192]) to stage1.blocks.0.norm1.weight (192,)\n",
      "set stage1.blocks.0.norm1.bias torch.Size([192]) to stage1.blocks.0.norm1.bias (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_q.conv.weight torch.Size([192, 1, 3, 3]) to stage1.blocks.0.attn.conv_proj_q.0.weight (192, 1, 3, 3)\n",
      "set stage1.blocks.0.attn.conv_proj_q.bn.weight torch.Size([192]) to stage1.blocks.0.attn.conv_proj_q.1.weight (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_q.bn.bias torch.Size([192]) to stage1.blocks.0.attn.conv_proj_q.1.bias (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_q.bn.running_mean torch.Size([192]) to stage1.blocks.0.attn.conv_proj_q.1._mean (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_q.bn.running_var torch.Size([192]) to stage1.blocks.0.attn.conv_proj_q.1._variance (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_k.conv.weight torch.Size([192, 1, 3, 3]) to stage1.blocks.0.attn.conv_proj_k.0.weight (192, 1, 3, 3)\n",
      "set stage1.blocks.0.attn.conv_proj_k.bn.weight torch.Size([192]) to stage1.blocks.0.attn.conv_proj_k.1.weight (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_k.bn.bias torch.Size([192]) to stage1.blocks.0.attn.conv_proj_k.1.bias (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_k.bn.running_mean torch.Size([192]) to stage1.blocks.0.attn.conv_proj_k.1._mean (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_k.bn.running_var torch.Size([192]) to stage1.blocks.0.attn.conv_proj_k.1._variance (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_v.conv.weight torch.Size([192, 1, 3, 3]) to stage1.blocks.0.attn.conv_proj_v.0.weight (192, 1, 3, 3)\n",
      "set stage1.blocks.0.attn.conv_proj_v.bn.weight torch.Size([192]) to stage1.blocks.0.attn.conv_proj_v.1.weight (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_v.bn.bias torch.Size([192]) to stage1.blocks.0.attn.conv_proj_v.1.bias (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_v.bn.running_mean torch.Size([192]) to stage1.blocks.0.attn.conv_proj_v.1._mean (192,)\n",
      "set stage1.blocks.0.attn.conv_proj_v.bn.running_var torch.Size([192]) to stage1.blocks.0.attn.conv_proj_v.1._variance (192,)\n",
      "set stage1.blocks.0.attn.proj_q.weight torch.Size([192, 192]) to stage1.blocks.0.attn.proj_q.weight (192, 192)\n",
      "set stage1.blocks.0.attn.proj_q.bias torch.Size([192]) to stage1.blocks.0.attn.proj_q.bias (192,)\n",
      "set stage1.blocks.0.attn.proj_k.weight torch.Size([192, 192]) to stage1.blocks.0.attn.proj_k.weight (192, 192)\n",
      "set stage1.blocks.0.attn.proj_k.bias torch.Size([192]) to stage1.blocks.0.attn.proj_k.bias (192,)\n",
      "set stage1.blocks.0.attn.proj_v.weight torch.Size([192, 192]) to stage1.blocks.0.attn.proj_v.weight (192, 192)\n",
      "set stage1.blocks.0.attn.proj_v.bias torch.Size([192]) to stage1.blocks.0.attn.proj_v.bias (192,)\n",
      "set stage1.blocks.0.attn.proj.weight torch.Size([192, 192]) to stage1.blocks.0.attn.proj.weight (192, 192)\n",
      "set stage1.blocks.0.attn.proj.bias torch.Size([192]) to stage1.blocks.0.attn.proj.bias (192,)\n",
      "set stage1.blocks.0.norm2.weight torch.Size([192]) to stage1.blocks.0.norm2.weight (192,)\n",
      "set stage1.blocks.0.norm2.bias torch.Size([192]) to stage1.blocks.0.norm2.bias (192,)\n",
      "set stage1.blocks.0.mlp.fc1.weight torch.Size([768, 192]) to stage1.blocks.0.mlp.fc1.weight (192, 768)\n",
      "set stage1.blocks.0.mlp.fc1.bias torch.Size([768]) to stage1.blocks.0.mlp.fc1.bias (768,)\n",
      "set stage1.blocks.0.mlp.fc2.weight torch.Size([192, 768]) to stage1.blocks.0.mlp.fc2.weight (768, 192)\n",
      "set stage1.blocks.0.mlp.fc2.bias torch.Size([192]) to stage1.blocks.0.mlp.fc2.bias (192,)\n",
      "set stage1.blocks.1.norm1.weight torch.Size([192]) to stage1.blocks.1.norm1.weight (192,)\n",
      "set stage1.blocks.1.norm1.bias torch.Size([192]) to stage1.blocks.1.norm1.bias (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_q.conv.weight torch.Size([192, 1, 3, 3]) to stage1.blocks.1.attn.conv_proj_q.0.weight (192, 1, 3, 3)\n",
      "set stage1.blocks.1.attn.conv_proj_q.bn.weight torch.Size([192]) to stage1.blocks.1.attn.conv_proj_q.1.weight (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_q.bn.bias torch.Size([192]) to stage1.blocks.1.attn.conv_proj_q.1.bias (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_q.bn.running_mean torch.Size([192]) to stage1.blocks.1.attn.conv_proj_q.1._mean (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_q.bn.running_var torch.Size([192]) to stage1.blocks.1.attn.conv_proj_q.1._variance (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_k.conv.weight torch.Size([192, 1, 3, 3]) to stage1.blocks.1.attn.conv_proj_k.0.weight (192, 1, 3, 3)\n",
      "set stage1.blocks.1.attn.conv_proj_k.bn.weight torch.Size([192]) to stage1.blocks.1.attn.conv_proj_k.1.weight (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_k.bn.bias torch.Size([192]) to stage1.blocks.1.attn.conv_proj_k.1.bias (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_k.bn.running_mean torch.Size([192]) to stage1.blocks.1.attn.conv_proj_k.1._mean (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_k.bn.running_var torch.Size([192]) to stage1.blocks.1.attn.conv_proj_k.1._variance (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_v.conv.weight torch.Size([192, 1, 3, 3]) to stage1.blocks.1.attn.conv_proj_v.0.weight (192, 1, 3, 3)\n",
      "set stage1.blocks.1.attn.conv_proj_v.bn.weight torch.Size([192]) to stage1.blocks.1.attn.conv_proj_v.1.weight (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_v.bn.bias torch.Size([192]) to stage1.blocks.1.attn.conv_proj_v.1.bias (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_v.bn.running_mean torch.Size([192]) to stage1.blocks.1.attn.conv_proj_v.1._mean (192,)\n",
      "set stage1.blocks.1.attn.conv_proj_v.bn.running_var torch.Size([192]) to stage1.blocks.1.attn.conv_proj_v.1._variance (192,)\n",
      "set stage1.blocks.1.attn.proj_q.weight torch.Size([192, 192]) to stage1.blocks.1.attn.proj_q.weight (192, 192)\n",
      "set stage1.blocks.1.attn.proj_q.bias torch.Size([192]) to stage1.blocks.1.attn.proj_q.bias (192,)\n",
      "set stage1.blocks.1.attn.proj_k.weight torch.Size([192, 192]) to stage1.blocks.1.attn.proj_k.weight (192, 192)\n",
      "set stage1.blocks.1.attn.proj_k.bias torch.Size([192]) to stage1.blocks.1.attn.proj_k.bias (192,)\n",
      "set stage1.blocks.1.attn.proj_v.weight torch.Size([192, 192]) to stage1.blocks.1.attn.proj_v.weight (192, 192)\n",
      "set stage1.blocks.1.attn.proj_v.bias torch.Size([192]) to stage1.blocks.1.attn.proj_v.bias (192,)\n",
      "set stage1.blocks.1.attn.proj.weight torch.Size([192, 192]) to stage1.blocks.1.attn.proj.weight (192, 192)\n",
      "set stage1.blocks.1.attn.proj.bias torch.Size([192]) to stage1.blocks.1.attn.proj.bias (192,)\n",
      "set stage1.blocks.1.norm2.weight torch.Size([192]) to stage1.blocks.1.norm2.weight (192,)\n",
      "set stage1.blocks.1.norm2.bias torch.Size([192]) to stage1.blocks.1.norm2.bias (192,)\n",
      "set stage1.blocks.1.mlp.fc1.weight torch.Size([768, 192]) to stage1.blocks.1.mlp.fc1.weight (192, 768)\n",
      "set stage1.blocks.1.mlp.fc1.bias torch.Size([768]) to stage1.blocks.1.mlp.fc1.bias (768,)\n",
      "set stage1.blocks.1.mlp.fc2.weight torch.Size([192, 768]) to stage1.blocks.1.mlp.fc2.weight (768, 192)\n",
      "set stage1.blocks.1.mlp.fc2.bias torch.Size([192]) to stage1.blocks.1.mlp.fc2.bias (192,)\n",
      "set stage2.patch_embed.proj.weight torch.Size([384, 192, 3, 3]) to stage2.patch_embed.proj.weight (384, 192, 3, 3)\n",
      "set stage2.patch_embed.proj.bias torch.Size([384]) to stage2.patch_embed.proj.bias (384,)\n",
      "set stage2.patch_embed.norm.weight torch.Size([384]) to stage2.patch_embed.norm.weight (384,)\n",
      "set stage2.patch_embed.norm.bias torch.Size([384]) to stage2.patch_embed.norm.bias (384,)\n",
      "set stage2.blocks.0.norm1.weight torch.Size([384]) to stage2.blocks.0.norm1.weight (384,)\n",
      "set stage2.blocks.0.norm1.bias torch.Size([384]) to stage2.blocks.0.norm1.bias (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.0.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.0.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.0.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.0.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.0.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.0.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.0.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.0.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.0.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.0.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.0.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.0.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.0.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.0.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.0.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.0.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.0.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.0.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.0.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.0.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.0.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.0.attn.proj_q.bias torch.Size([384]) to stage2.blocks.0.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.0.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.0.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.0.attn.proj_k.bias torch.Size([384]) to stage2.blocks.0.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.0.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.0.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.0.attn.proj_v.bias torch.Size([384]) to stage2.blocks.0.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.0.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.0.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.0.attn.proj.bias torch.Size([384]) to stage2.blocks.0.attn.proj.bias (384,)\n",
      "set stage2.blocks.0.norm2.weight torch.Size([384]) to stage2.blocks.0.norm2.weight (384,)\n",
      "set stage2.blocks.0.norm2.bias torch.Size([384]) to stage2.blocks.0.norm2.bias (384,)\n",
      "set stage2.blocks.0.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.0.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.0.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.0.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.0.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.0.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.0.mlp.fc2.bias torch.Size([384]) to stage2.blocks.0.mlp.fc2.bias (384,)\n",
      "set stage2.blocks.1.norm1.weight torch.Size([384]) to stage2.blocks.1.norm1.weight (384,)\n",
      "set stage2.blocks.1.norm1.bias torch.Size([384]) to stage2.blocks.1.norm1.bias (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.1.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.1.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.1.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.1.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.1.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.1.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.1.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.1.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.1.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.1.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.1.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.1.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.1.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.1.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.1.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.1.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.1.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.1.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.1.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.1.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.1.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.1.attn.proj_q.bias torch.Size([384]) to stage2.blocks.1.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.1.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.1.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.1.attn.proj_k.bias torch.Size([384]) to stage2.blocks.1.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.1.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.1.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.1.attn.proj_v.bias torch.Size([384]) to stage2.blocks.1.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.1.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.1.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.1.attn.proj.bias torch.Size([384]) to stage2.blocks.1.attn.proj.bias (384,)\n",
      "set stage2.blocks.1.norm2.weight torch.Size([384]) to stage2.blocks.1.norm2.weight (384,)\n",
      "set stage2.blocks.1.norm2.bias torch.Size([384]) to stage2.blocks.1.norm2.bias (384,)\n",
      "set stage2.blocks.1.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.1.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.1.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.1.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.1.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.1.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.1.mlp.fc2.bias torch.Size([384]) to stage2.blocks.1.mlp.fc2.bias (384,)\n",
      "set stage2.blocks.2.norm1.weight torch.Size([384]) to stage2.blocks.2.norm1.weight (384,)\n",
      "set stage2.blocks.2.norm1.bias torch.Size([384]) to stage2.blocks.2.norm1.bias (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.2.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.2.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.2.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.2.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.2.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.2.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.2.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.2.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.2.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.2.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.2.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.2.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.2.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.2.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.2.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.2.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.2.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.2.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.2.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.2.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.2.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.2.attn.proj_q.bias torch.Size([384]) to stage2.blocks.2.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.2.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.2.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.2.attn.proj_k.bias torch.Size([384]) to stage2.blocks.2.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.2.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.2.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.2.attn.proj_v.bias torch.Size([384]) to stage2.blocks.2.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.2.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.2.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.2.attn.proj.bias torch.Size([384]) to stage2.blocks.2.attn.proj.bias (384,)\n",
      "set stage2.blocks.2.norm2.weight torch.Size([384]) to stage2.blocks.2.norm2.weight (384,)\n",
      "set stage2.blocks.2.norm2.bias torch.Size([384]) to stage2.blocks.2.norm2.bias (384,)\n",
      "set stage2.blocks.2.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.2.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.2.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.2.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.2.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.2.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.2.mlp.fc2.bias torch.Size([384]) to stage2.blocks.2.mlp.fc2.bias (384,)\n",
      "set stage2.blocks.3.norm1.weight torch.Size([384]) to stage2.blocks.3.norm1.weight (384,)\n",
      "set stage2.blocks.3.norm1.bias torch.Size([384]) to stage2.blocks.3.norm1.bias (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.3.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.3.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.3.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.3.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.3.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.3.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.3.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.3.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.3.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.3.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.3.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.3.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.3.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.3.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.3.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.3.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.3.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.3.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.3.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.3.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.3.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.3.attn.proj_q.bias torch.Size([384]) to stage2.blocks.3.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.3.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.3.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.3.attn.proj_k.bias torch.Size([384]) to stage2.blocks.3.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.3.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.3.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.3.attn.proj_v.bias torch.Size([384]) to stage2.blocks.3.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.3.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.3.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.3.attn.proj.bias torch.Size([384]) to stage2.blocks.3.attn.proj.bias (384,)\n",
      "set stage2.blocks.3.norm2.weight torch.Size([384]) to stage2.blocks.3.norm2.weight (384,)\n",
      "set stage2.blocks.3.norm2.bias torch.Size([384]) to stage2.blocks.3.norm2.bias (384,)\n",
      "set stage2.blocks.3.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.3.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.3.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.3.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.3.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.3.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.3.mlp.fc2.bias torch.Size([384]) to stage2.blocks.3.mlp.fc2.bias (384,)\n",
      "set stage2.blocks.4.norm1.weight torch.Size([384]) to stage2.blocks.4.norm1.weight (384,)\n",
      "set stage2.blocks.4.norm1.bias torch.Size([384]) to stage2.blocks.4.norm1.bias (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.4.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.4.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.4.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.4.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.4.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.4.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.4.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.4.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.4.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.4.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.4.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.4.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.4.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.4.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.4.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.4.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.4.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.4.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.4.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.4.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.4.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.4.attn.proj_q.bias torch.Size([384]) to stage2.blocks.4.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.4.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.4.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.4.attn.proj_k.bias torch.Size([384]) to stage2.blocks.4.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.4.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.4.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.4.attn.proj_v.bias torch.Size([384]) to stage2.blocks.4.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.4.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.4.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.4.attn.proj.bias torch.Size([384]) to stage2.blocks.4.attn.proj.bias (384,)\n",
      "set stage2.blocks.4.norm2.weight torch.Size([384]) to stage2.blocks.4.norm2.weight (384,)\n",
      "set stage2.blocks.4.norm2.bias torch.Size([384]) to stage2.blocks.4.norm2.bias (384,)\n",
      "set stage2.blocks.4.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.4.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.4.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.4.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.4.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.4.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.4.mlp.fc2.bias torch.Size([384]) to stage2.blocks.4.mlp.fc2.bias (384,)\n",
      "set stage2.blocks.5.norm1.weight torch.Size([384]) to stage2.blocks.5.norm1.weight (384,)\n",
      "set stage2.blocks.5.norm1.bias torch.Size([384]) to stage2.blocks.5.norm1.bias (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.5.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.5.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.5.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.5.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.5.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.5.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.5.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.5.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.5.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.5.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.5.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.5.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.5.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.5.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.5.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.5.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.5.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.5.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.5.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.5.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.5.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.5.attn.proj_q.bias torch.Size([384]) to stage2.blocks.5.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.5.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.5.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.5.attn.proj_k.bias torch.Size([384]) to stage2.blocks.5.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.5.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.5.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.5.attn.proj_v.bias torch.Size([384]) to stage2.blocks.5.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.5.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.5.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.5.attn.proj.bias torch.Size([384]) to stage2.blocks.5.attn.proj.bias (384,)\n",
      "set stage2.blocks.5.norm2.weight torch.Size([384]) to stage2.blocks.5.norm2.weight (384,)\n",
      "set stage2.blocks.5.norm2.bias torch.Size([384]) to stage2.blocks.5.norm2.bias (384,)\n",
      "set stage2.blocks.5.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.5.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.5.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.5.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.5.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.5.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.5.mlp.fc2.bias torch.Size([384]) to stage2.blocks.5.mlp.fc2.bias (384,)\n",
      "set stage2.blocks.6.norm1.weight torch.Size([384]) to stage2.blocks.6.norm1.weight (384,)\n",
      "set stage2.blocks.6.norm1.bias torch.Size([384]) to stage2.blocks.6.norm1.bias (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.6.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.6.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.6.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.6.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.6.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.6.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.6.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.6.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.6.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.6.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.6.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.6.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.6.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.6.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.6.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.6.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.6.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.6.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.6.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.6.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.6.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.6.attn.proj_q.bias torch.Size([384]) to stage2.blocks.6.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.6.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.6.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.6.attn.proj_k.bias torch.Size([384]) to stage2.blocks.6.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.6.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.6.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.6.attn.proj_v.bias torch.Size([384]) to stage2.blocks.6.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.6.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.6.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.6.attn.proj.bias torch.Size([384]) to stage2.blocks.6.attn.proj.bias (384,)\n",
      "set stage2.blocks.6.norm2.weight torch.Size([384]) to stage2.blocks.6.norm2.weight (384,)\n",
      "set stage2.blocks.6.norm2.bias torch.Size([384]) to stage2.blocks.6.norm2.bias (384,)\n",
      "set stage2.blocks.6.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.6.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.6.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.6.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.6.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.6.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.6.mlp.fc2.bias torch.Size([384]) to stage2.blocks.6.mlp.fc2.bias (384,)\n",
      "set stage2.blocks.7.norm1.weight torch.Size([384]) to stage2.blocks.7.norm1.weight (384,)\n",
      "set stage2.blocks.7.norm1.bias torch.Size([384]) to stage2.blocks.7.norm1.bias (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.7.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.7.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.7.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.7.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.7.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.7.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.7.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.7.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.7.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.7.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.7.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.7.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.7.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.7.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.7.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.7.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.7.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.7.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.7.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.7.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.7.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.7.attn.proj_q.bias torch.Size([384]) to stage2.blocks.7.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.7.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.7.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.7.attn.proj_k.bias torch.Size([384]) to stage2.blocks.7.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.7.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.7.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.7.attn.proj_v.bias torch.Size([384]) to stage2.blocks.7.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.7.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.7.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.7.attn.proj.bias torch.Size([384]) to stage2.blocks.7.attn.proj.bias (384,)\n",
      "set stage2.blocks.7.norm2.weight torch.Size([384]) to stage2.blocks.7.norm2.weight (384,)\n",
      "set stage2.blocks.7.norm2.bias torch.Size([384]) to stage2.blocks.7.norm2.bias (384,)\n",
      "set stage2.blocks.7.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.7.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.7.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.7.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.7.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.7.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.7.mlp.fc2.bias torch.Size([384]) to stage2.blocks.7.mlp.fc2.bias (384,)\n",
      "set stage2.blocks.8.norm1.weight torch.Size([384]) to stage2.blocks.8.norm1.weight (384,)\n",
      "set stage2.blocks.8.norm1.bias torch.Size([384]) to stage2.blocks.8.norm1.bias (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.8.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.8.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.8.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.8.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.8.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.8.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.8.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.8.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.8.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.8.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.8.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.8.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.8.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.8.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.8.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.8.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.8.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.8.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.8.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.8.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.8.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.8.attn.proj_q.bias torch.Size([384]) to stage2.blocks.8.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.8.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.8.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.8.attn.proj_k.bias torch.Size([384]) to stage2.blocks.8.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.8.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.8.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.8.attn.proj_v.bias torch.Size([384]) to stage2.blocks.8.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.8.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.8.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.8.attn.proj.bias torch.Size([384]) to stage2.blocks.8.attn.proj.bias (384,)\n",
      "set stage2.blocks.8.norm2.weight torch.Size([384]) to stage2.blocks.8.norm2.weight (384,)\n",
      "set stage2.blocks.8.norm2.bias torch.Size([384]) to stage2.blocks.8.norm2.bias (384,)\n",
      "set stage2.blocks.8.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.8.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.8.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.8.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.8.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.8.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.8.mlp.fc2.bias torch.Size([384]) to stage2.blocks.8.mlp.fc2.bias (384,)\n",
      "set stage2.blocks.9.norm1.weight torch.Size([384]) to stage2.blocks.9.norm1.weight (384,)\n",
      "set stage2.blocks.9.norm1.bias torch.Size([384]) to stage2.blocks.9.norm1.bias (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_q.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.9.attn.conv_proj_q.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.9.attn.conv_proj_q.bn.weight torch.Size([384]) to stage2.blocks.9.attn.conv_proj_q.1.weight (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_q.bn.bias torch.Size([384]) to stage2.blocks.9.attn.conv_proj_q.1.bias (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_q.bn.running_mean torch.Size([384]) to stage2.blocks.9.attn.conv_proj_q.1._mean (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_q.bn.running_var torch.Size([384]) to stage2.blocks.9.attn.conv_proj_q.1._variance (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_k.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.9.attn.conv_proj_k.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.9.attn.conv_proj_k.bn.weight torch.Size([384]) to stage2.blocks.9.attn.conv_proj_k.1.weight (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_k.bn.bias torch.Size([384]) to stage2.blocks.9.attn.conv_proj_k.1.bias (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_k.bn.running_mean torch.Size([384]) to stage2.blocks.9.attn.conv_proj_k.1._mean (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_k.bn.running_var torch.Size([384]) to stage2.blocks.9.attn.conv_proj_k.1._variance (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_v.conv.weight torch.Size([384, 1, 3, 3]) to stage2.blocks.9.attn.conv_proj_v.0.weight (384, 1, 3, 3)\n",
      "set stage2.blocks.9.attn.conv_proj_v.bn.weight torch.Size([384]) to stage2.blocks.9.attn.conv_proj_v.1.weight (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_v.bn.bias torch.Size([384]) to stage2.blocks.9.attn.conv_proj_v.1.bias (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_v.bn.running_mean torch.Size([384]) to stage2.blocks.9.attn.conv_proj_v.1._mean (384,)\n",
      "set stage2.blocks.9.attn.conv_proj_v.bn.running_var torch.Size([384]) to stage2.blocks.9.attn.conv_proj_v.1._variance (384,)\n",
      "set stage2.blocks.9.attn.proj_q.weight torch.Size([384, 384]) to stage2.blocks.9.attn.proj_q.weight (384, 384)\n",
      "set stage2.blocks.9.attn.proj_q.bias torch.Size([384]) to stage2.blocks.9.attn.proj_q.bias (384,)\n",
      "set stage2.blocks.9.attn.proj_k.weight torch.Size([384, 384]) to stage2.blocks.9.attn.proj_k.weight (384, 384)\n",
      "set stage2.blocks.9.attn.proj_k.bias torch.Size([384]) to stage2.blocks.9.attn.proj_k.bias (384,)\n",
      "set stage2.blocks.9.attn.proj_v.weight torch.Size([384, 384]) to stage2.blocks.9.attn.proj_v.weight (384, 384)\n",
      "set stage2.blocks.9.attn.proj_v.bias torch.Size([384]) to stage2.blocks.9.attn.proj_v.bias (384,)\n",
      "set stage2.blocks.9.attn.proj.weight torch.Size([384, 384]) to stage2.blocks.9.attn.proj.weight (384, 384)\n",
      "set stage2.blocks.9.attn.proj.bias torch.Size([384]) to stage2.blocks.9.attn.proj.bias (384,)\n",
      "set stage2.blocks.9.norm2.weight torch.Size([384]) to stage2.blocks.9.norm2.weight (384,)\n",
      "set stage2.blocks.9.norm2.bias torch.Size([384]) to stage2.blocks.9.norm2.bias (384,)\n",
      "set stage2.blocks.9.mlp.fc1.weight torch.Size([1536, 384]) to stage2.blocks.9.mlp.fc1.weight (384, 1536)\n",
      "set stage2.blocks.9.mlp.fc1.bias torch.Size([1536]) to stage2.blocks.9.mlp.fc1.bias (1536,)\n",
      "set stage2.blocks.9.mlp.fc2.weight torch.Size([384, 1536]) to stage2.blocks.9.mlp.fc2.weight (1536, 384)\n",
      "set stage2.blocks.9.mlp.fc2.bias torch.Size([384]) to stage2.blocks.9.mlp.fc2.bias (384,)\n",
      "set norm.weight torch.Size([384]) to norm.weight (384,)\n",
      "set norm.bias torch.Size([384]) to norm.bias (384,)\n",
      "set head.weight torch.Size([1000, 384]) to head.weight (384, 1000)\n",
      "set head.bias torch.Size([1000]) to head.bias (1000,)\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "(2, 1000) (2, 1000)\n",
      "[-0.3800164   0.04475065  0.00210959  0.04976563  0.6249806   0.5376348\n",
      "  0.39623982  0.09941574  0.05197333 -0.13147283 -0.15551502 -0.12418604\n",
      " -0.001736   -0.1324093   0.16521195 -0.12623388  0.10615312 -0.23827343\n",
      " -0.15447502 -0.3341366 ]\n",
      "[-0.3800164   0.0447499   0.00210886  0.04976541  0.62498     0.5376335\n",
      "  0.39623916  0.09941518  0.05197294 -0.13147281 -0.1555147  -0.12418568\n",
      " -0.00173637 -0.13240904  0.16521195 -0.12623382  0.10615303 -0.23827308\n",
      " -0.15447462 -0.33413634]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import paddle\n",
    "from cvt_torch import cls_cvt\n",
    "from cvt_torch import default \n",
    "\n",
    "from config import get_config\n",
    "from cvt1 import build_cvt as build_model\n",
    "\n",
    "paddle.set_device('cpu')\n",
    "\n",
    "\n",
    "def print_model_named_params(model):\n",
    "    print('----------------------------------')\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.shape)\n",
    "    print('----------------------------------')\n",
    "\n",
    "\n",
    "def print_model_named_buffers(model):\n",
    "    print('----------------------------------')\n",
    "    for name, param in model.named_buffers():\n",
    "        print(name, param.shape)\n",
    "    print('----------------------------------')\n",
    "\n",
    "def torch_to_paddle_mapping():\n",
    "    mapping = [('stage2.cls_token', 'stage2.cls_token')]\n",
    "\n",
    "    # torch 'layers' to  paddle 'stages'\n",
    "    depths = [1, 2, 10]\n",
    "    num_stages = len(depths)\n",
    "    for stage_idx in range(num_stages):\n",
    "        pp_s_prefix = f'stage{stage_idx}'\n",
    "        th_s_prefix = f'stage{stage_idx}'\n",
    "        layer_mapping = [\n",
    "            (f'{th_s_prefix}.patch_embed.proj', f'{pp_s_prefix}.patch_embed.proj'),\n",
    "            (f'{th_s_prefix}.patch_embed.norm', f'{pp_s_prefix}.patch_embed.norm'),\n",
    "        ] \n",
    "        mapping.extend(layer_mapping)\n",
    "\n",
    "        for block_idx in range(depths[stage_idx]):\n",
    "            th_b_prefix = f'{th_s_prefix}.blocks.{block_idx}'\n",
    "            pp_b_prefix = f'{pp_s_prefix}.blocks.{block_idx}'\n",
    "            layer_mapping = [\n",
    "                (f'{th_b_prefix}.norm1', f'{pp_b_prefix}.norm1'),\n",
    "                (f'{th_b_prefix}.attn.conv_proj_q.conv', f'{pp_b_prefix}.attn.conv_proj_q.0'),\n",
    "                (f'{th_b_prefix}.attn.conv_proj_q.bn', f'{pp_b_prefix}.attn.conv_proj_q.1'),\n",
    "                (f'{th_b_prefix}.attn.conv_proj_k.conv', f'{pp_b_prefix}.attn.conv_proj_k.0'),\n",
    "                (f'{th_b_prefix}.attn.conv_proj_k.bn', f'{pp_b_prefix}.attn.conv_proj_k.1'),\n",
    "                (f'{th_b_prefix}.attn.conv_proj_v.conv', f'{pp_b_prefix}.attn.conv_proj_v.0'),\n",
    "                (f'{th_b_prefix}.attn.conv_proj_v.bn', f'{pp_b_prefix}.attn.conv_proj_v.1'),\n",
    "                (f'{th_b_prefix}.attn.proj_q', f'{pp_b_prefix}.attn.proj_q'),\n",
    "                (f'{th_b_prefix}.attn.proj_k', f'{pp_b_prefix}.attn.proj_k'),\n",
    "                (f'{th_b_prefix}.attn.proj_v', f'{pp_b_prefix}.attn.proj_v'),\n",
    "                (f'{th_b_prefix}.attn.proj', f'{pp_b_prefix}.attn.proj'),\n",
    "                (f'{th_b_prefix}.norm2', f'{pp_b_prefix}.norm2'),\n",
    "                (f'{th_b_prefix}.mlp.fc1', f'{pp_b_prefix}.mlp.fc1'),\n",
    "                (f'{th_b_prefix}.mlp.fc2', f'{pp_b_prefix}.mlp.fc2'),\n",
    "            ]\n",
    "            mapping.extend(layer_mapping)\n",
    "\n",
    "    mapping.extend([\n",
    "        ('norm', 'norm'),\n",
    "        ('head', 'head')])\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def convert(torch_model, paddle_model):\n",
    "    def _set_value(th_name, pd_name, no_transpose=False):\n",
    "        th_shape = th_params[th_name].shape\n",
    "        pd_shape = tuple(pd_params[pd_name].shape) # paddle shape default type is list\n",
    "        #assert th_shape == pd_shape, f'{th_shape} != {pd_shape}'\n",
    "        print(f'set {th_name} {th_shape} to {pd_name} {pd_shape}')\n",
    "        value = th_params[th_name].data.numpy()\n",
    "        if len(value.shape) == 2:\n",
    "            if not no_transpose:\n",
    "                value = value.transpose((1, 0))\n",
    "        pd_params[pd_name].set_value(value)\n",
    "\n",
    "    # 1. get paddle and torch model parameters\n",
    "    pd_params = {}\n",
    "    th_params = {}\n",
    "    for name, param in paddle_model.named_parameters():\n",
    "        pd_params[name] = param\n",
    "    for name, param in torch_model.named_parameters():\n",
    "        th_params[name] = param\n",
    "\n",
    "    for name, param in paddle_model.named_buffers():\n",
    "        pd_params[name] = param\n",
    "    for name, param in torch_model.named_buffers():\n",
    "        th_params[name] = param\n",
    "\n",
    "    # 2. get name mapping pairs\n",
    "    mapping = torch_to_paddle_mapping()\n",
    "\n",
    "\n",
    "    # 3. set torch param values to paddle params: may needs transpose on weights\n",
    "    for th_name, pd_name in mapping:\n",
    "        if th_name in th_params.keys(): # nn.Parameters\n",
    "            if th_name.endswith('relative_position_bias_table'):\n",
    "                _set_value(th_name, pd_name, no_transpose=True)\n",
    "            else:\n",
    "                _set_value(th_name, pd_name)\n",
    "        else: # weight & bias\n",
    "            if f'{th_name}.weight' in th_params.keys():\n",
    "                th_name_w = f'{th_name}.weight'\n",
    "                pd_name_w = f'{pd_name}.weight'\n",
    "                _set_value(th_name_w, pd_name_w)\n",
    "\n",
    "            if f'{th_name}.bias' in th_params.keys():\n",
    "                th_name_b = f'{th_name}.bias'\n",
    "                pd_name_b = f'{pd_name}.bias'\n",
    "                _set_value(th_name_b, pd_name_b)\n",
    "\n",
    "            if f'{th_name}.running_mean' in th_params.keys():\n",
    "                th_name_b = f'{th_name}.running_mean'\n",
    "                pd_name_b = f'{pd_name}._mean'\n",
    "                _set_value(th_name_b, pd_name_b)\n",
    "\n",
    "            if f'{th_name}.running_var' in th_params.keys():\n",
    "                th_name_b = f'{th_name}.running_var'\n",
    "                pd_name_b = f'{pd_name}._variance'\n",
    "                _set_value(th_name_b, pd_name_b)\n",
    "\n",
    "    return paddle_model\n",
    "\n",
    "def main():\n",
    "    paddle.set_device('cpu')\n",
    "    paddle_config = get_config('./configs/cvt-13-224x224.yaml')\n",
    "    paddle_model = build_model(paddle_config)\n",
    "    paddle_model.eval()\n",
    "\n",
    "    print_model_named_params(paddle_model)\n",
    "    print_model_named_buffers(paddle_model)\n",
    "\n",
    "    print('+++++++++++++++++++++++++++++++++++')\n",
    "    device = torch.device('cpu')\n",
    "    torch_config = default.get_config('./cvt_torch/cvt-13-224x224.yaml')\n",
    "    torch_model = cls_cvt.get_cls_model(torch_config)\n",
    "    state_dict = torch.load('./cvt_torch/CvT-13-224x224-IN-1k.pth', map_location=lambda storage, loc: storage)\n",
    "    torch_model.load_state_dict(state_dict)\n",
    "    torch_model = torch_model.to(device)\n",
    "    torch_model.eval()\n",
    "    print_model_named_params(torch_model)\n",
    "    print_model_named_buffers(torch_model)\n",
    "\n",
    "    # convert weights\n",
    "    paddle_model = convert(torch_model, paddle_model)\n",
    "\n",
    "    # check correctness\n",
    "    x = np.random.randn(2, 3, 224, 224).astype('float32')\n",
    "    x_paddle = paddle.to_tensor(x)\n",
    "    x_torch = torch.Tensor(x).to(device)\n",
    "\n",
    "    out_torch = torch_model(x_torch)\n",
    "    print('|||||||||||||||||||||||||||||||||||||||||||||||||||')\n",
    "    print('|||||||||||||||||||||||||||||||||||||||||||||||||||')\n",
    "    print('|||||||||||||||||||||||||||||||||||||||||||||||||||')\n",
    "    out_paddle = paddle_model(x_paddle)\n",
    "\n",
    "    out_torch = out_torch.data.cpu().numpy()\n",
    "    out_paddle = out_paddle.cpu().numpy()\n",
    "\n",
    "    print(out_torch.shape, out_paddle.shape)\n",
    "    print(out_torch[0, 0:20])\n",
    "    print(out_paddle[0, 0:20])\n",
    "    assert np.allclose(out_torch, out_paddle, atol = 1e-2)\n",
    "\n",
    "    # save weights for paddle model\n",
    "    model_path = os.path.join('./cvt_13_new.pdparams')\n",
    "    paddle.save(paddle_model.state_dict(), model_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "632b173250d16d6f9b5bd55f86a0e0c96b37a21df53bd488615da0bb1f86a5c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('cvt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
