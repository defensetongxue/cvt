{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging config from ./config_cvt/config.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "import torch\n",
    "import os\n",
    "from config_cvt.default import get_config\n",
    "import torchvision.models as models\n",
    "from cvt import generate_model\n",
    "from cvt_torch import get_cls_model\n",
    "model_name = 'CvT-13-224x224-IN-1k.pth'\n",
    "\n",
    "config=get_config('./config_cvt/config.yaml')\n",
    "paddle.set_device('cpu')\n",
    "paddle_model = generate_model(config)\n",
    "paddle_model.eval()\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch_model= get_cls_model(config)\n",
    "torch_model.load_state_dict= torch.load(model_name,map_location=torch.device('cpu'))\n",
    "\n",
    "torch_model = torch_model.to(device)\n",
    "torch_model.eval()\n",
    "file_debug=open('debug.txt','w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_to_paddle_mapping(torch_model,paddle_model):\n",
    "    paddle_array=[]\n",
    "    torch_array=[]\n",
    "    for i,value in torch_model.state_dict().items():\n",
    "        torch_array.append((i,value.shape))\n",
    "\n",
    "    for i,value in paddle_model.state_dict().items():\n",
    "        paddle_array.append((i,value.shape))\n",
    "\n",
    "    j=0\n",
    "    mapping=[]\n",
    "    def equel(i,j):\n",
    "        x:str=torch_array[i][0]\n",
    "        y:str=paddle_array[j][0]\n",
    "        if x==y:\n",
    "            return True\n",
    "        x=x.replace('.bn.','.1.')\n",
    "        x=x.replace('.conv.','.0.')\n",
    "        x=x.replace('.running_mean','._mean')\n",
    "        x=x.replace('.running_var','._variance')\n",
    "        if x==y:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    for i in range(len(torch_array)):\n",
    "        if equel(i,j):\n",
    "            mapping.append((torch_array[i][0],paddle_array[j][0]))\n",
    "            j+=1\n",
    "    if len(mapping)!=len(paddle_array):\n",
    "        assert RuntimeError(f'mapping is not full,length of mapping is{len(mapping)},length of paddle_array is {len(paddle_array)}')\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(torch_model, paddle_model):\n",
    "    def _set_value(th_name, pd_name, transpose=True):\n",
    "        th_shape = th_params[th_name].shape\n",
    "        pd_shape = tuple(pd_params[pd_name].shape) \n",
    "\n",
    "        file_debug.write(f'**SET** {th_name} {th_shape} **TO** {pd_name} {pd_shape}')\n",
    "        file_debug.write('\\n')\n",
    "        if isinstance(th_params[th_name], torch.nn.parameter.Parameter):\n",
    "            value = th_params[th_name].data.numpy()\n",
    "        else:\n",
    "            value = th_params[th_name].numpy()\n",
    "\n",
    "        if len(value.shape) == 2 and transpose:\n",
    "            value = value.transpose((1, 0))\n",
    "        pd_params[pd_name].set_value(value)\n",
    "\n",
    "    # 1. get paddle and torch model parameters\n",
    "    pd_params = {}\n",
    "    th_params = {}\n",
    "    for name, param in paddle_model.named_parameters():\n",
    "        pd_params[name] = param\n",
    "    for name, param in torch_model.named_parameters():\n",
    "        th_params[name] = param\n",
    "\n",
    "    for name, param in paddle_model.named_buffers():\n",
    "        pd_params[name] = param\n",
    "    for name, param in torch_model.named_buffers():\n",
    "        th_params[name] = param\n",
    "\n",
    "    # 2. get name mapping pairs\n",
    "    mapping = torch_to_paddle_mapping(torch_model,paddle_model)\n",
    "\n",
    "    # 3. set torch param values to paddle params: may needs transpose on weights\n",
    "    for th_name, pd_name in mapping:\n",
    "        if th_name in th_params.keys(): # nn.Parameters\n",
    "            _set_value(th_name, pd_name)\n",
    "        else: # weight & bias\n",
    "            th_name_w = f'{th_name}.weight'\n",
    "            pd_name_w = f'{pd_name}.weight'\n",
    "            _set_value(th_name_w, pd_name_w)\n",
    "\n",
    "            if f'{th_name}.bias' in th_params.keys():\n",
    "                th_name_b = f'{th_name}.bias'\n",
    "                pd_name_b = f'{pd_name}.bias'\n",
    "                _set_value(th_name_b, pd_name_b)\n",
    "\n",
    "    return paddle_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9808/1897632003.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mfile_debug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_torch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_paddle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# save weights for paddle model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# convert weights\n",
    "paddle_model = convert(torch_model, paddle_model)\n",
    "\n",
    "# check correctness\n",
    "x = np.random.randn(2, 3, 224, 224).astype('float32')\n",
    "x_paddle = paddle.to_tensor(x)\n",
    "x_torch = torch.Tensor(x).to(device)\n",
    "\n",
    "out_torch = torch_model(x_torch)\n",
    "out_paddle = paddle_model(x_paddle)\n",
    "\n",
    "out_torch = out_torch.data.cpu().numpy()\n",
    "out_paddle = out_paddle.cpu().numpy()\n",
    "\n",
    "file_debug.write(str(out_torch.shape))\n",
    "file_debug.write('\\n')\n",
    "file_debug.write( str(out_paddle.shape))\n",
    "file_debug.write('\\n')\n",
    "file_debug.write(str(out_torch[0, 0:100]))\n",
    "file_debug.write('\\n')\n",
    "file_debug.write('========================================================')\n",
    "file_debug.write('\\n')\n",
    "file_debug.write(str(out_paddle[0, 0:100]))\n",
    "file_debug.write('\\n')\n",
    "\n",
    "assert np.allclose(out_torch, out_paddle, atol = 1e-5)\n",
    "\n",
    "# save weights for paddle model\n",
    "model_path = os.path.join(f'./{model_name}.pdparams')\n",
    "paddle.save(paddle_model.state_dict(), model_path)\n",
    "file_debug.write('all done')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "632b173250d16d6f9b5bd55f86a0e0c96b37a21df53bd488615da0bb1f86a5c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('cvt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
